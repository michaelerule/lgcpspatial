{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "altered-participation",
   "metadata": {},
   "source": [
    "## Low-rank approximation \n",
    "\n",
    "We consider an approximate posterior covariance of the form\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\boldsymbol\\Sigma^{-1} &\\approx \\mathbf X \\mathbf X^\\top,\\,\\,\\,\\,\\mathbf X\\in\\mathbb R^{L^2\\times K}\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "where $\\mathbf X$ is a tall, thin matrix, with as many rows as there are spatial bins ($L^2$), and $K<L^2$ columns. We view $\\mathbf X$ as being composed of $L^2$ length-$K$ row-vectors $\\mathbf x_k$. \n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\mathbf X^\\top &= \\{ \\mathbf x_1^\\top,...,\\mathbf x_{L^2}^\\top \\}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-shipping",
   "metadata": {},
   "source": [
    "Neglecting terms that do not depend on $\\mathbf X$, the loss to be minimized is:\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\mathcal L(\\mathbf X)&=\\mathbf n^\\top \\exp\\left(\\boldsymbol\\mu + \\tfrac 1 2 \\operatorname{diag}\\left[\\mathbf X \\mathbf X^\\top\\right]\\right)+ \\tfrac 1 2 \\left \\{ \\operatorname{tr}\\left[\\boldsymbol\\Sigma_0^{-1}\\mathbf X \\mathbf X^\\top\\right] - \\ln|\\mathbf X^\\top \\mathbf X |\\right\\}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-first",
   "metadata": {},
   "source": [
    "Note that we have used $\\ln|\\mathbf X^\\top \\mathbf X |$ above, rather than $\\ln|\\mathbf X\\mathbf X^\\top|$\n",
    "Since $\\mathbf X \\mathbf X^\\top$ is rank $K<L^2$, it always as a subspace of size $L^2-K$ with zero eigenvalues. This null space doesn't affect the gradient, but it does make the log-determinant undefined. $\\ln|\\mathbf X^\\top \\mathbf X |$ considers only the log-determinant in the low-rank space spanned by $\\mathbf X$, and remains finite. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-twist",
   "metadata": {},
   "source": [
    "\\begin{equation}\\begin{aligned}\n",
    "%%%% GRADIENT IN v\n",
    "\\operatorname{\\nabla}_{\\mathbf X}\n",
    "\\mathcal L &=\n",
    "\\left(\n",
    "\\operatorname{diag}\\left[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle\\right] + \\boldsymbol\\Sigma_0^{-1}\\right)\\mathbf X - {\\mathbf X^{+}}^\\top\n",
    "\\end{aligned}\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-knife",
   "metadata": {},
   "source": [
    "The derivatives of $\\operatorname{tr}\\left[\\boldsymbol\\Sigma_0^{-1}\\mathbf X \\mathbf X^\\top\\right]$ and $\\ln|\\mathbf X \\mathbf X^\\top|$ can be found in The Matrix Cookbook. The gradient of $\\mathbf n^\\top \\exp\\left(\\boldsymbol\\mu+ \\tfrac 1 2 \\operatorname{diag}\\left[\\mathbf X \\mathbf X^\\top\\right]\\right)$ can be solved manually by considering single elements of $\\mathbf X$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-portal",
   "metadata": {},
   "source": [
    "\\begin{equation}\\begin{aligned}\n",
    "\\tfrac{d}{dx_{ij}}\n",
    "\\mathbf n^\\top \\exp\\left(\\boldsymbol\\mu+ \\tfrac 1 2 \\operatorname{diag}\\left[\\mathbf X \\mathbf X^\\top\\right]\\right)\n",
    "&=\n",
    "\\textstyle\\sum_l n_l\\langle\\lambda_l\\rangle\n",
    "\\tfrac12 \\tfrac{d}{dx_{ij}} \\operatorname{diag}\\left[\\mathbf X \\mathbf X^\\top\\right]_l\n",
    "\\\\&=\n",
    "\\textstyle\\sum_l n_l\\langle\\lambda_l\\rangle\n",
    "\\tfrac12\\sum_k \\tfrac{d}{dx_{ij}} \\mathbf x_{lk}^2\n",
    "\\\\&=\n",
    "\\textstyle\\sum_l n_l\\langle\\lambda_l\\rangle\n",
    "\\tfrac12\\sum_k 2 \\mathbf x_{lk} \\delta_{ij=lk}\n",
    "\\\\&=\n",
    "\\textstyle\\sum_l n_l\\langle\\lambda_l\\rangle\n",
    "\\mathbf x_{lj} \\delta_{i=l}\n",
    "\\\\&=\n",
    "n_i\\langle\\lambda_i\\rangle \\mathbf x_{ij}\n",
    "\\\\&=\n",
    "\\left[\\operatorname{diag}[\\mathbf n\\circ \\langle\\boldsymbol\\lambda\\rangle]\\, \\mathbf X\\right]_{ij}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-pencil",
   "metadata": {},
   "source": [
    "Writing down the Hessian in $\\mathbf X$ is cumbersome, since it is four-dimensional. However, in practice we only need to calculate the product of the Hessian with a \"vector\", which is in this case a matrix $\\mathbf M$: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-tsunami",
   "metadata": {},
   "source": [
    "\\begin{equation}\\begin{aligned}\n",
    "{}\\left[\\operatorname{H}_{\\mathbf v} \\mathcal L \\right]{\\mathbf M}\n",
    "=\\operatorname{diag}\\left[\\mathbf n \\circ \\langle\\boldsymbol\\lambda\\rangle\\right]\n",
    "\\left[ \\mathbf I\\circ\\mathbf M\\mathbf X^\\top + \\mathbf M \\right]\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-favor",
   "metadata": {},
   "source": [
    "Proving this is horrifying. This can be obtained by differentiating the scalar product between the Jacobian and a matrix $\\mathbf M$, $\\operatorname{tr}\\left\\{\\left[\\operatorname{\\nabla}_{\\mathbf X} \\mathcal L\\right]^\\top \\mathbf M\\right\\}$: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-secondary",
   "metadata": {},
   "source": [
    "\\begin{equation}\\begin{aligned}\n",
    "\\operatorname{\\nabla}_{\\mathbf X} \\operatorname{tr}\\left\\{\n",
    "\\left[\\operatorname{\\nabla}_{\\mathbf X}\n",
    "\\mathcal L\\right]^\\top \\mathbf M\\right\\} \n",
    "&=\n",
    "\\operatorname{\\nabla}_{\\mathbf X} \\operatorname{tr}\\left\\{\n",
    "\\left[\\left(\\operatorname{diag}\\left[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle\\right] + \\boldsymbol\\Sigma_0^{-1}\\right)\\mathbf X - {\\mathbf X^{+}}^\\top\\right]^\\top \\mathbf M\\right\\}\n",
    "\\\\&=\n",
    "\\operatorname{\\nabla}_{\\mathbf X} \\operatorname{tr}\\left\\{\n",
    "\\left[\\mathbf X^\\top\\left(\\operatorname{diag}\\left[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle\\right] + \\boldsymbol\\Sigma_0^{-1}\\right) - \\mathbf X^{+}\\right] \\mathbf M\\right\\}\n",
    "\\\\&=\n",
    "\\operatorname{\\nabla}_{\\mathbf X} \n",
    "\\operatorname{tr}\\left\\{\n",
    "\\mathbf X^\\top\\left(\\operatorname{diag}\\left[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle\\right] + \\boldsymbol\\Sigma_0^{-1}\\right)\\mathbf M - \\mathbf X^{+}\\mathbf M\\right\\}\n",
    "\\\\\n",
    "&=\n",
    "\\operatorname{\\nabla}_{\\mathbf X}\\operatorname{tr}\\left\\{\n",
    "\\mathbf X^\\top\\operatorname{diag}\\left[\n",
    "\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle\n",
    "\\right]\\mathbf M\n",
    "\\right\\}\n",
    "+\n",
    "\\operatorname{\\nabla}_{\\mathbf X}\\operatorname{tr}\\left\\{\n",
    "\\mathbf X^\\top\\boldsymbol\\Sigma_0^{-1}\\mathbf M\n",
    "\\right\\}\n",
    "- \n",
    "\\operatorname{\\nabla}_{\\mathbf X}\\operatorname{tr}\\left\\{\n",
    "\\mathbf M\\mathbf X^{+}\n",
    "\\right\\}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-transformation",
   "metadata": {},
   "source": [
    "How the hell did you derive this? Is it even correct? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-start",
   "metadata": {},
   "source": [
    "It is necessary to derive this element-wise. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-prison",
   "metadata": {},
   "source": [
    "\\begin{equation}\\begin{aligned}\n",
    "\\frac{d}{d x_{ij}} \\mathbf n^\\top \\langle\\boldsymbol\\lambda\\rangle\n",
    "&=\n",
    "\\frac{d}{d x_{ij}} \\mathbf n^\\top \\exp\\left(\\boldsymbol\\mu + \\tfrac 1 2 \\operatorname{diag}\\left[\\mathbf X \\mathbf X^\\top\\right]\\right)\n",
    "\\\\&=\n",
    "\\frac{d}{d x_{ij}} \\sum_k n_k \\exp\\left(\\mu_k + \\tfrac 1 2 \\operatorname{diag}\\left[\\mathbf X \\mathbf X^\\top\\right]_k\\right)\n",
    "\\\\&=\n",
    "\\frac{d}{d x_{ij}} \\sum_l n_l \\exp\\left(\\mu_l + \\tfrac 1 2 \\sum_k x_{lk}^2 \\right)\n",
    "\\\\&=\n",
    "\\sum_l n_l \\frac{d}{d x_{ij}}\\exp\\left(\\mu_l + \\tfrac 1 2 \\sum_k x_{lk}^2 \\right)\n",
    "\\\\&=\n",
    "\\sum_l n_l \\langle\\lambda_l\\rangle \\tfrac 1 2 \\sum_k \\frac{d}{d x_{ij}} x_{lk}^2\n",
    "\\\\&=\n",
    "\\sum_l n_l \\langle\\lambda_l\\rangle \\sum_k x_{lk} \\delta_{lk=ij}\n",
    "\\\\&=\n",
    "\\sum_l n_l \\langle\\lambda_l\\rangle x_{lj} \\delta_{l=i}\n",
    "\\\\&=\n",
    "n_i \\langle\\lambda_i\\rangle x_{ij}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-sunset",
   "metadata": {},
   "source": [
    "\\begin{equation}\\begin{aligned}\n",
    "\\frac{d}{d x_{kl}}\n",
    "\\frac{d}{d x_{ij}} \\mathbf n^\\top \\langle\\boldsymbol\\lambda\\rangle\n",
    "&=\n",
    "\\frac{d}{d x_{kl}} n_i \\langle\\lambda_i\\rangle x_{ij}\n",
    "\\\\&=\n",
    "n_i \\frac{d}{d x_{kl}} \\langle\\lambda_i\\rangle \n",
    "+n_i \\langle\\lambda_i\\rangle \\frac{d}{d x_{kl}} x_{ij}\n",
    "\\\\&=\n",
    "n_i \\langle\\lambda_i\\rangle \\tfrac 1 2 \\frac{d}{d x_{kl}} \\operatorname{diag}\\left[\\mathbf X \\mathbf X^\\top\\right]_i\n",
    "+n_i \\langle\\lambda_i\\rangle \\delta_{ij=kl}\n",
    "\\\\&=\n",
    "n_i \\langle\\lambda_i\\rangle \\tfrac 1 2 \n",
    "\\sum_m \\frac{d}{d x_{kl}}  \\mathbf x_{im}^2\n",
    "+n_i \\langle\\lambda_i\\rangle \\delta_{ij=kl}\n",
    "\\\\&=\n",
    "n_i \\langle\\lambda_i\\rangle\n",
    "\\sum_m \\mathbf x_{im} \\delta_{im=kl}\n",
    "+n_i \\langle\\lambda_i\\rangle \\delta_{ij=kl}\n",
    "\\\\&=\n",
    "n_i \\langle\\lambda_i\\rangle\n",
    "\\mathbf x_{il} \\delta_{i=k}\n",
    "+n_i \\langle\\lambda_i\\rangle \\delta_{ij=kl}\n",
    "\\\\&=\n",
    "\\delta_{i=k}(\n",
    "n_i \\langle\\lambda_i\\rangle\n",
    "\\mathbf x_{il} \n",
    "+n_i \\langle\\lambda_i\\rangle \\delta_{j=l}\n",
    ")\n",
    "\\end{aligned}\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-hometown",
   "metadata": {},
   "source": [
    "Scalar product with $\\mathbf M$ ($m_{ij} = (\\mathbf M)_{ij}$). We apply this on the left. \n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\left<\\frac{d}{d x_{kl}}\n",
    "\\frac{d}{d x_{ij}} \\mathbf n^\\top \\langle\\boldsymbol\\lambda\\rangle, \n",
    "\\, \n",
    "\\mathbf M \\right>_{kl}\n",
    "&=\n",
    "\\sum_{ij} m_{ij}\n",
    "\\delta_{i=k}(\n",
    "n_i \\langle\\lambda_i\\rangle\n",
    "\\mathbf x_{il} \n",
    "+n_i \\langle\\lambda_i\\rangle \\delta_{j=l}\n",
    ")\n",
    "\\\\&=\n",
    "\\sum_{j} m_{kj}\n",
    "(\n",
    "n_k \\langle\\lambda_k\\rangle\n",
    "\\mathbf x_{kl} \n",
    "+n_k \\langle\\lambda_k\\rangle \\delta_{j=l}\n",
    ")\n",
    "\\\\&=\n",
    "\\sum_{j} m_{kj}\n",
    "n_k \\langle\\lambda_k\\rangle\n",
    "\\mathbf x_{kl} \n",
    "+\n",
    "\\sum_{j} m_{kj}\n",
    "n_k \\langle\\lambda_k\\rangle \\delta_{j=l}\n",
    "\\\\&=\n",
    "n_k \\langle\\lambda_k\\rangle\n",
    "\\mathbf x_{kl} \\sum_{j} m_{kj}\n",
    "+\n",
    "m_{kl}\n",
    "n_k \\langle\\lambda_k\\rangle\n",
    "\\\\&=\n",
    "n_k \\langle\\lambda_k\\rangle \\left[\n",
    "\\mathbf x_{kl} \\sum_{j} m_{kj}\n",
    "+\n",
    "m_{kl}\n",
    "\\right]\n",
    "\\\\&=\n",
    "\\left\\{\n",
    "\\operatorname{diag}\\left[\\mathbf n \\langle\\boldsymbol\\lambda\\rangle\\right]\n",
    "\\left[\n",
    "\\operatorname{diag}[\\mathbf M \\mathbb 1]\\, \\mathbf X\n",
    "+\n",
    "\\mathbf M\n",
    "\\right]\n",
    "\\right\\}_{kl}\n",
    "\\end{aligned}\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-mainland",
   "metadata": {},
   "source": [
    "\\begin{equation}\\begin{aligned}\n",
    "\\tfrac 1 2 \\left \\{ \\operatorname{tr}\\left[\\boldsymbol\\Sigma_0^{-1}\\mathbf X \\mathbf X^\\top\\right] - \\ln|\\mathbf X^\\top \\mathbf X |\\right\\}\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\boldsymbol\\Sigma_0^{-1}\\mathbf X - \\mathbf X^{-\\top}\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\operatorname{tr}[\n",
    "\\mathbf X^\\top \\boldsymbol\\Sigma_0^{-1}\\mathbf M - \\mathbf X^{-1}\\mathbf M\n",
    "]\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\boldsymbol\\Sigma_0^{-1}\\mathbf M + \\mathbf X^{-1}\\mathbf M^\\top \\mathbf X^{-1}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-entry",
   "metadata": {},
   "source": [
    "We can work with just $\\mathbf X$ as full rank, invertable, but we do need to be able to ake its inverse. This seems to imply that the inverse will diverse if $\\mathbf X$ ever takes on a value that is low-rank. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-transportation",
   "metadata": {},
   "source": [
    "\\begin{equation}\\begin{aligned}\n",
    "\\mathcal L(\\mathbf v)&=\\mathbf n^\\top \\exp\\left(\\boldsymbol\\mu + \\tfrac 1 2 \\operatorname{diag}[\\boldsymbol\\Sigma]\\right)+ \\tfrac 1 2 \\left \\{ \\operatorname{tr}[\\boldsymbol\\Sigma_0^{-1}\\boldsymbol\\Sigma] - \\ln|\\boldsymbol\\Sigma|\\right\\}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-hollow",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-fitting",
   "metadata": {},
   "source": [
    "## Reduced Fourier-space approximation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-hobby",
   "metadata": {},
   "source": [
    "\\begin{equation}\\begin{aligned}\n",
    "\\mathcal L(\\mathbf v)&=\\mathbf n^\\top \\exp\\left(\\boldsymbol\\mu + \\tfrac 1 2 \\operatorname{diag}[\\boldsymbol\\Sigma]\\right)+ \\tfrac 1 2 \\left \\{ \\operatorname{tr}[\\boldsymbol\\Sigma_0^{-1}\\boldsymbol\\Sigma] - \\ln|\\boldsymbol\\Sigma|\\right\\}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-attendance",
   "metadata": {},
   "source": [
    "We consider an approximate posterior covariance of the form\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\boldsymbol\\Sigma &\\approx \\mathbf F^\\top \\mathbf Q \\mathbf Q^\\top \\mathbf F,\n",
    "\\,\\,\\,\\,\\mathbf Q\\in\\mathbb R^{K\\times K}\n",
    "\\end{aligned}\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-automation",
   "metadata": {},
   "source": [
    "Neglecting terms that do not depend on $\\mathbf Q$, the loss to be minimized is:\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\mathcal L(\\mathbf X)&=\\mathbf n^\\top \\exp\\left(\\boldsymbol\\mu + \\tfrac 1 2 \\operatorname{diag}\\left[\\mathbf F^\\top \\mathbf Q \\mathbf Q^\\top \\mathbf F\\right]\\right)+ \\tfrac 1 2 \\left \\{ \\operatorname{tr}\\left[\\boldsymbol\\Sigma_0^{-1}\\mathbf F^\\top \\mathbf Q \\mathbf Q^\\top \\mathbf F\\right] - \\ln| \\mathbf Q \\mathbf Q^\\top |\\right\\}\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\frac{d}{d\\sigma_{ij}} \\left\\{ \\mathbf n^\\top \\exp\\left(\\boldsymbol\\mu + \\tfrac 1 2 \\operatorname{diag}[\\boldsymbol\\Sigma]\\right)+ \\tfrac 1 2 \\left \\{ \\operatorname{tr}[\\boldsymbol\\Sigma_0^{-1}\\boldsymbol\\Sigma] - \\ln|\\boldsymbol\\Sigma|\\right\\}\n",
    "\\right\\}\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\mathbf n^\\top \\frac{d}{d\\sigma_{ij}} \\exp\\left(\\boldsymbol\\mu + \\tfrac 1 2 \\operatorname{diag}[\\boldsymbol\\Sigma]\\right)\n",
    "+ \n",
    "\\frac 1 2 \\frac{d}{d\\sigma_{ij}} \\operatorname{tr}[\\boldsymbol\\Sigma_0^{-1}\\boldsymbol\\Sigma] \n",
    "- \n",
    "\\frac 1 2 \\frac{d}{d\\sigma_{ij}} \\ln|\\boldsymbol\\Sigma|\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\frac{\\partial\\mathcal L}{\\partial\\Sigma_{ij}}\n",
    "\\tfrac 1 2\\left\\{\\operatorname{diag}[\\mathbf n \\lambda ]+ \\boldsymbol\\Sigma_0^{-1}- \\boldsymbol\\Sigma^{-\\top}\\right\\}_{ij}\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "$$\n",
    "\\frac{\\partial\\mathcal L}{\\partial\\theta_i} = \n",
    "\\operatorname{tr}\\left[\n",
    "\\left(\\frac{\\partial\\mathcal L}{\\partial\\boldsymbol\\Sigma}\n",
    "\\right)^\\top\n",
    "\\frac{\\partial\\boldsymbol\\Sigma}{\\partial \\theta_i}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\mathbf F^\\top  (\\mathbf J^{ij}\\mathbf Q^\\top + \\mathbf Q \\mathbf J^{ji}) \\mathbf F\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "$$\n",
    "\\frac{\\partial\\mathcal L}{\\partial\\theta_i} = \\tfrac 1 2\n",
    "\\operatorname{tr}\\left[\n",
    "\\left(\n",
    "%\n",
    "\\operatorname{diag}[\\mathbf n \\lambda ]+ \\boldsymbol\\Sigma_0^{-1}- \\boldsymbol\\Sigma^{-1}\n",
    "%\n",
    "\\right)\n",
    "\\mathbf F^\\top  (\\mathbf J^{ij}\\mathbf Q^\\top + \\mathbf Q \\mathbf J^{ji}) \\mathbf F\n",
    "\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-bulgaria",
   "metadata": {},
   "source": [
    "$$\n",
    "2QFF^\\top\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-roberts",
   "metadata": {},
   "source": [
    "$A J^{ij}$ puts $i$th column of $A$ in column $j$\n",
    "\n",
    "$J^{ij}A$ puts row $j$ of $A$  in row $i$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-aberdeen",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac\n",
    "{\\partial(\\mathbf F^\\top \\mathbf Q \\mathbf Q^\\top \\mathbf F)_{ij}}\n",
    "{\\partial\\mathbf Q_{kl}}\n",
    "=\n",
    "\\sum_m F_{ki} F_{mj} Q_{ml}\n",
    "+\n",
    "F_{mi} F_{kj} Q_{ml}\n",
    "=\n",
    "F_{ki} (F^\\top Q)_{jl}\n",
    "+\n",
    "F_{kj} (F^\\top Q)_{il}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-manor",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial\\mathcal L}{\\partial\\mathbf Q_{kl}} = \\tfrac 1 2\n",
    "\\operatorname{tr}\\left[\n",
    "\\left(\n",
    "%\n",
    "\\operatorname{diag}[\\mathbf n \\lambda ]+ \\boldsymbol\\Sigma_0^{-1}- \\boldsymbol\\Sigma^{-1}\n",
    "%\n",
    "\\right)\n",
    "\\mathbf F^\\top  (\\mathbf J^{ij}\\mathbf Q^\\top + \\mathbf Q \\mathbf J^{ji}) \\mathbf F\n",
    "\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-replica",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sum_m [F_{ki} F_{mj} \n",
    "+\n",
    "F_{mi} F_{kj}] Q_{ml}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-superior",
   "metadata": {},
   "source": [
    "$$\n",
    "{Q^\\top F A F^\\top]_{qp}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-company",
   "metadata": {},
   "source": [
    "# We need a way to verify derivatives. \n",
    "\n",
    "I'm not sure I feel like .. let's just.. ones. \n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\mathcal L(\\boldsymbol\\mu,\\boldsymbol\\Sigma)\n",
    "&=\n",
    "\\mathbf n^\\top \\left[\\langle\\boldsymbol\\lambda\\rangle-\\bar{\\mathbf y} \\circ \\boldsymbol\\mu\\right]\n",
    "+ \n",
    "\\tfrac 1 2 \\left \\{ \\operatorname{tr}[\\boldsymbol\\Sigma_0^{-1}\\boldsymbol\\Sigma] + \n",
    "{\\boldsymbol\\mu}^\\top{{\\boldsymbol\\Sigma}_0}^{-1}\\boldsymbol\\mu\n",
    "+ \\ln|\\boldsymbol\\Sigma_0| - \\ln|\\boldsymbol\\Sigma|\n",
    "\\right\\}\n",
    "\\\\\n",
    "\\langle\\boldsymbol\\lambda\\rangle &=\n",
    "\\exp\\left(\n",
    "\\boldsymbol\\mu+\\boldsymbol\\mu_0\n",
    "+\n",
    "\\tfrac 1 2 \\operatorname{diag}\\left[\\boldsymbol\\Sigma\\right]\\right)\n",
    "\\end{aligned}\n",
    "\\label{loss}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "general-giving",
   "metadata": {},
   "source": [
    "## Variational Bayes: Low-rank approximation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-romance",
   "metadata": {},
   "source": [
    "We consider an approximate posterior covariance of the form\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\boldsymbol\\Sigma^{-1} &\\approx \\mathbf X \\mathbf X^\\top,\\,\\,\\,\\,\\mathbf X\\in\\mathbb R^{L^2\\times K}\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "where $\\mathbf X$ is a tall, thin matrix, with as many rows as there are spatial bins ($L^2$), and $K<L^2$ columns. We view $\\mathbf X$ as being composed of $L^2$ length-$K$ row-vectors $\\mathbf x_k$. \n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\mathbf X^\\top &= \\{ \\mathbf x_1^\\top,...,\\mathbf x_{L^2}^\\top \\}\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "Neglecting terms that do not depend on $\\mathbf X$, the loss to be minimized is:\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\mathcal L(\\mathbf X)&=\\mathbf n^\\top \\exp\\left(\\boldsymbol\\mu + \\tfrac 1 2 \\operatorname{diag}\\left[\\mathbf X \\mathbf X^\\top\\right]\\right)+ \\tfrac 1 2 \\left \\{ \\operatorname{tr}\\left[\\boldsymbol\\Sigma_0^{-1}\\mathbf X \\mathbf X^\\top\\right] - \\ln|\\mathbf X^\\top \\mathbf X |\\right\\}\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "Note that we have used $\\ln|\\mathbf X^\\top \\mathbf X |$ above, rather than $\\ln|\\mathbf X\\mathbf X^\\top|$\n",
    "Since $\\mathbf X \\mathbf X^\\top$ is rank $K<L^2$, it always as a subspace of size $L^2-K$ with zero eigenvalues. This null space doesn't affect the gradient, but it does make the log-determinant undefined. $\\ln|\\mathbf X^\\top \\mathbf X |$ considers only the log-determinant in the low-rank space spanned by $\\mathbf X$, and remains finite. The Jacobian is:\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "%%%% GRADIENT IN v\n",
    "\\operatorname{\\nabla}_{\\mathbf X}\n",
    "\\mathcal L &=\n",
    "\\left(\n",
    "\\operatorname{diag}\\left[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle\\right] + \\boldsymbol\\Sigma_0^{-1}\\right)\\mathbf X - {\\mathbf X^{+}}^\\top\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "\n",
    "The derivatives of $\\operatorname{tr}\\left[\\boldsymbol\\Sigma_0^{-1}\\mathbf X \\mathbf X^\\top\\right]$ and $\\ln|\\mathbf X \\mathbf X^\\top|$ can be found in The Matrix Cookbook. The gradient of $\\mathbf n^\\top \\exp\\left(\\boldsymbol\\mu+ \\tfrac 1 2 \\operatorname{diag}\\left[\\mathbf X \\mathbf X^\\top\\right]\\right)$ can be solved by considering single elements of $\\mathbf X$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-imaging",
   "metadata": {},
   "source": [
    "The Hessian-vector product is\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\operatorname{\\nabla}_{\\mathbf X} \\left< \\operatorname{\\nabla}_{\\mathbf X}, \\mathbf M \\right>\n",
    "\\mathcal L \n",
    "&=\n",
    "\\operatorname{\\nabla}_{\\mathbf X} \\left< \n",
    "\\left(\n",
    "\\operatorname{diag}\\left[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle\\right] + \\boldsymbol\\Sigma_0^{-1}\\right)\\mathbf X - {\\mathbf X^{+}}^\\top\n",
    ", \\mathbf M \\right>\n",
    "\\\\\n",
    "&=\n",
    "\\operatorname{\\nabla}_{\\mathbf X}\n",
    "\\operatorname{tr}\\left[\n",
    "\\mathbf X^\\top\n",
    "\\operatorname{diag}\\left[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle\\right]\\mathbf M\n",
    "+ \n",
    "\\mathbf X^\\top \\boldsymbol\\Sigma_0^{-1}\\mathbf M\n",
    "- \n",
    "{\\mathbf X^{+}}\\mathbf M\n",
    "\\right]\n",
    "\\\\\n",
    "&=\n",
    "\\operatorname{diag}\\left[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle\\right]\\mathbf M\n",
    "+ \n",
    "\\boldsymbol\\Sigma_0^{-1}\\mathbf M\n",
    "+{\\mathbf X^+}^\\top \\mathbf M^\\top {\\mathbf X^+}^\\top - (\\mathbf I - {\\mathbf X^+}^\\top \\mathbf X^\\top) \\mathbf M \\mathbf X^+ {\\mathbf X^+}^\\top\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "The derivative involving the pseudoinverse is given in Goulob and Pereya (1972) Eq. 4.12."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
