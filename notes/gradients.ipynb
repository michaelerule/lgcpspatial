{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c299b2a-5372-41db-a41f-28167de396e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from util   import *\n",
    "from basics import *\n",
    "from simulate_data import *\n",
    "from estimators    import *\n",
    "from config import *\n",
    "from scipy.special import *\n",
    "configure_pylab()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50527156-0c0b-459a-9b43-98f73ff27109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "MathJax.Hub.Config({\n",
       "    TeX: { equationNumbers: { autoNumber: \"AMS\" } }\n",
       "});\n",
       "MathJax.Hub.Queue(\n",
       "  [\"resetEquationNumbers\", MathJax.InputJax.TeX],\n",
       "  [\"PreProcess\", MathJax.Hub],\n",
       "  [\"Reprocess\", MathJax.Hub]\n",
       ");\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "MathJax.Hub.Config({\n",
    "    TeX: { equationNumbers: { autoNumber: \"AMS\" } }\n",
    "});\n",
    "MathJax.Hub.Queue(\n",
    "  [\"resetEquationNumbers\", MathJax.InputJax.TeX],\n",
    "  [\"PreProcess\", MathJax.Hub],\n",
    "  [\"Reprocess\", MathJax.Hub]\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469fb7cc-e8ce-40f1-a6c5-08a95ab98813",
   "metadata": {},
   "source": [
    "# Variational Bayes\n",
    "\n",
    "The posterior mode can be a good solution if the prior is appropriately chosen. However, the Laplace approximation is not accurate enough to estimate model likelihood and optimize prior hyperparameters when they are known. This is because the Laplace approximation uses the curvature at the posterior mode to approximate the posterior covariance. This approximation is inaccurate when the posterior is highly skewed. \n",
    "\n",
    "To select hyperparameters, we employ variational Bayes. This optimizes the mean and covariance of a Gaussian approximation to the posterior, $q(\\mathbf z)$, to minimize the Kullback-Liebler divergence from the true posterior $p(\\mathbf z)$ to this Gaussian approximation.\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "p(\\mathbf z) &= \\Pr(\\mathbf z | \\mathbf y) = \\Pr( \\mathbf y | \\mathbf z ) \\frac{\\Pr(\\mathbf z)}{\\Pr(\\mathbf y)}\n",
    "\\\\\n",
    "q(\\mathbf z) &\\sim \\mathcal N( \\boldsymbol\\mu, \\boldsymbol \\Sigma)\n",
    "\\\\\n",
    "q(\\mathbf z) &= \\underset{\\boldsymbol\\mu, \\boldsymbol \\Sigma}{\\operatorname{argmin}}\n",
    "D_{\\text{KL}}\\left[ q(\\mathbf z) \\| p(\\mathbf z) \n",
    "\\right]\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701a92ff-d760-4e98-89f2-c85994308387",
   "metadata": {},
   "source": [
    "Minimizing KL divergence is equivalent to maximizing the negative log-likelihood of the observations $\\mathbf y$, averaged over $q(\\mathbf z)$, while simultaneously minimizing the KL divergence from the prior $\\Pr(\\mathbf z)$ to the approximating posterior. \n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "D_{\\text{KL}}[q(\\mathbf z) \\| p(\\mathbf z)] \n",
    "&= -\\left< \\ln\\Pr(\\mathbf y|\\mathbf z)\\right>\n",
    "+ D_{\\text{KL}}[q(\\mathbf z) \\| \\Pr(\\mathbf z)]\n",
    "+ \\text{constant}\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "above (and throught this manuscript) expectations $\\langle\\cdot\\rangle$ are taken with respect to the approximate posterior $q(\\mathbf z)$ unless otherwise stated. \n",
    "\n",
    "Optimizing the full posterior covariance $\\boldsymbol \\Sigma$ is intractable. For example, the covariance for a a 100Ã—100 spatial grid contains $10^8$ entries. Instead, we explore various parameterizations of $\\boldsymbol \\Sigma$ which balance computational tractability with expressiveness. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59808109-642e-4789-817f-d5ca28619358",
   "metadata": {},
   "source": [
    "We evaluate the following approximations for the posterior covariance: \n",
    "1. A diagonal approximation $\\boldsymbol\\Sigma\\approx\\mathbf A^\\top \\operatorname{diag}[\\mathbf v] \\mathbf A$, where $\\mathbf A$ is a fixed spatial convolution. We choose $\\mathbf A$ to be a local Gaussian blur. This assumes that correlations are local, and and that there is a high-frequency cutoff in their spatial scale. It will not capture long-range correlations. This has complexity $\\mathcal O(L^2 \\log(L))$, where $L$ is the linear spatial dimension. (TODO: check complexity after writing code)\n",
    "2. An inverse diagonal approximation $\\boldsymbol\\Sigma\\approx[\\boldsymbol\\Sigma_0 + \\operatorname{diag}[\\mathbf p]]^{-1}$, where $\\boldsymbol\\Sigma_0$ is the prior covariance and $\\mathbf p$ is a vector of the inverse variance (precision) at each spatial location. This form resembles the Laplace approximation with a covariance correction. This has complexity ???. (TODO: check complexity after writing code)\n",
    "3. A low-rank approximation $\\boldsymbol\\Sigma\\approx\\mathbf X\\mathbf X^\\top$, where $\\mathbf X$ is a tall, thin matrix. This captures the principle subspace of $\\boldsymbol\\Sigma$. This has complexity $\\mathcal O(L^2 K)$, where $L$ is the linear spatial dimension and $K$ is the number of components in $\\mathbf X$. (TODO: check complexity after writing code)\n",
    "4. A reduced Fourier-space representation $\\mathbf F^\\top \\mathbf Q \\mathbf Q^\\top \\mathbf F$, where $\\mathbf F$ is the unitary 2D Fourier transform, with frequencies that are zero in the prior $\\boldsymbol\\Sigma_0$ discarded, and $\\mathbf Q$ is a (lower? upper? TODO) triangular matrix. Since the posterior cannot assign probability mass where the prior $\\boldsymbol\\Sigma_0$ is zero, this fully parameterizes $\\boldsymbol Q$ in a compact way. The Fourier transform can be computed quickly using the Fast Fourier Transform (FFT). Complex values in $\\mathbf Q$ can be avoided by using the Discrete Cosine Transform (DCT).  This has complexity $\\mathcal O(L^2 \\log(L) K^3)$, where $L$ is the linear spatial dimension and $K$ is the rank of $\\mathbf Q$. (TODO: check complexity after writing code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9473c6e-919b-4edc-ba4b-21e7d64ef66a",
   "metadata": {},
   "source": [
    "In the following sections, we derive closed-form expressions for the gradient and Hessian of each of these models. But first, we write down the general form for $D_{\\text{KL}}(q(z) \\| p(z))$ in the case of a log-Gaussian Cox process. \n",
    "\n",
    "We employ a Poisson observation model, which models the firing intensity $\\lambda_i$ at each location $i$ as an exponential function of the estimate log-rate $z_i$, plus the prior mean $\\mu_{0,i}$ (which we assume is fixed).\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\Pr\\left(\\textstyle\\int_t^{t+\\Delta t} y(t)\\, dt = k\\right) &\\sim \\operatorname{Poisson}\\left(\\textstyle\\int_t^{t+\\Delta} \\lambda(t)\\, dt\\right)\n",
    "=\n",
    "\\frac{1}{k!} \\lambda^k e^{-\\lambda}.\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "If the animal is at location $i$ at time $t$, then the probability of observing $y$ spikes is\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\Pr(y_t) &\\sim \\operatorname{Poisson}\\left[ \\lambda_i = e^{z_i+\\mu_{0,i}} \\right]\n",
    "\\\\\n",
    "\\ln\\Pr(y_t)&= y_t \\ln(\\lambda_i)-\\lambda_i + \\text{constant}\n",
    "\\\\\n",
    "&= y_t z_i - e^{z_i+\\mu_{0,i}} + \\text{constant}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e1ec37-ee10-4566-9a3c-c83442b0eaa0",
   "metadata": {},
   "source": [
    "Above, constant terms that depend only on the observations $\\mathbf y$ are omitted as they do not change the solution. The overall log-likelihood is a sum of this Poisson log-likehood for all observations. We simplify this sum by averaging observations in the same bin together: \n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "T_i &= \\{ t \\mid \\mathbf x_t \\text{ in bin }i  \\}\\\\\n",
    "n_i &= |T_i|,\n",
    "\\\\\n",
    "\\bar y_i &= \\tfrac 1 {n_i} \\textstyle\\sum_{t \\in T_i} y_t,\n",
    "\\end{aligned}\n",
    "\\\\\n",
    "\\textstyle\\sum_{t \\in T_i} \\left[y_t \\ln(\\lambda_i) - \\lambda_i\\right]\n",
    "= n_i \\left[ \\bar y_i \\ln(\\lambda_i) - \\lambda_i \\right].\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fa6a6e-2ef4-4ecf-9025-48fcbf88a3e4",
   "metadata": {},
   "source": [
    "This can be written in vector notation as \n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\ln \\Pr(\\mathbf y | \\mathbf z)\n",
    "&= \\mathbf n^\\top \\left( \\bar{\\mathbf y} \\circ \\mathbf z - \\boldsymbol\\lambda \\right) + \\text{constant},\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "where $\\mathbf n$ is a vector of the number of visits to each locatoin, and  $\\circ$ denotes element-wise multiplication. Since $q(\\mathbf z)$ is Gaussian, the expectation $\\langle\\ln \\Pr(\\mathbf y | \\mathbf z)\\rangle$ has a closed-form solution based on the log-normal distribution:\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\left< \\ln p(\\mathbf y | \\mathbf z) \\right>_{q(\\mathbf z)} \n",
    "&= \\langle\n",
    "\\mathbf n^\\top \\left( \\bar{\\mathbf y} \\circ \\mathbf z - \\boldsymbol\\lambda \\right)\n",
    "\\rangle + \\text{constant}\n",
    "\\\\\n",
    "&= \n",
    "\\mathbf n^\\top( \\bar{\\mathbf y} \\circ \\boldsymbol\\mu)\n",
    "- \\mathbf n^\\top\\langle\\boldsymbol\\lambda\\rangle + \\text{constant}\n",
    "\\\\\n",
    "&= \n",
    "\\mathbf n^\\top \\left[\\bar{\\mathbf y} \\circ \\boldsymbol\\mu\n",
    "- \\exp\\left(\\boldsymbol\\mu_0 + \\tfrac 1 2 \\operatorname{diag}[\\boldsymbol\\Sigma]\\right)\\right] + \\text{constant.}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e363fddb-536a-41ba-b1cb-b1eda1e40b48",
   "metadata": {},
   "source": [
    "Next, we need to compute $D_{\\text{KL}}[q(\\mathbf z) \\| \\Pr(\\mathbf z)]$ with respect to $q(\\mathbf z)$. Since both the prior and posterior are multivariate Gaussians, this has a closed form: \n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "D_{\\text{KL}}[q(\\mathbf z) \\| \\Pr(\\mathbf z)]\n",
    "&=\n",
    "\\tfrac 1 2 \\left \\{ \\operatorname{tr}[\\boldsymbol\\Sigma_0^{-1}\\boldsymbol\\Sigma] + \n",
    "{(\\boldsymbol\\mu-\\boldsymbol\\mu_0)}^\\top{{\\boldsymbol\\Sigma}_0}^{-1}(\\boldsymbol\\mu-\\boldsymbol\\mu_0)\n",
    "+ \\ln|\\boldsymbol\\Sigma_0| - \\ln|\\boldsymbol\\Sigma|\n",
    "\\right\\}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4192a405-5686-4f7a-99a9-07b5016c3794",
   "metadata": {},
   "source": [
    "Up to constants, then, the loss function that we must minimize is: \n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\mathcal L(\\boldsymbol\\mu,\\boldsymbol\\Sigma)\n",
    "&=\n",
    "\\mathbf n^\\top \\left[\\langle\\boldsymbol\\lambda\\rangle-\\bar{\\mathbf y} \\circ \\boldsymbol\\mu\\right]\n",
    "+ \n",
    "\\tfrac 1 2 \\left \\{ \\operatorname{tr}[\\boldsymbol\\Sigma_0^{-1}\\boldsymbol\\Sigma] + \n",
    "{(\\boldsymbol\\mu-\\boldsymbol\\mu_0)}^\\top{{\\boldsymbol\\Sigma}_0}^{-1}(\\boldsymbol\\mu-\\boldsymbol\\mu_0)\n",
    "+ \\ln|\\boldsymbol\\Sigma_0| - \\ln|\\boldsymbol\\Sigma|\n",
    "\\right\\}\n",
    "\\end{aligned}\n",
    "\\label{loss}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d4db0e-b237-44ce-803a-1ad005407af7",
   "metadata": {},
   "source": [
    "The precise form for this loss function, and its derivatives, depends on the choice of approximation for $\\boldsymbol\\Sigma$, as we detail in the following sections. However, the derivatives in $\\boldsymbol\\mu$ are always the same, and similar to the gradients for the MAP estimator with the expected rate $\\langle\\boldsymbol\\lambda\\rangle$ replacing $\\boldsymbol\\lambda$:\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "%%%% GRADIENT IN Î¼\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\mu}\n",
    "\\mathcal L &=\n",
    "\\mathbf n \\circ (\\langle\\boldsymbol\\lambda\\rangle - \\mathbf y)\n",
    "+\\boldsymbol\\Sigma_0^{-1}(\\boldsymbol\\mu-\\boldsymbol\\mu_0)\n",
    "\\\\\n",
    "%%%% HESSIAN IN Î¼\n",
    "\\operatorname{H}_{\\boldsymbol \\mu}\n",
    "\\mathcal L &=\n",
    "\\operatorname{diag}[\\mathbf n \\circ \\langle\\boldsymbol\\lambda\\rangle]\n",
    "+\\boldsymbol\\Sigma_0^{-1}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e943b0-04d2-4762-b6d0-1af6495aaf7f",
   "metadata": {},
   "source": [
    "# Gradients of the posterior covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6181ae4d-74d1-4f75-9243-376cdfc2b542",
   "metadata": {},
   "source": [
    "Neglecting terms that do not depend on $\\boldsymbol\\Sigma$, the loss to be minimized is:\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\mathcal L(\\boldsymbol\\Sigma) &=\n",
    "\\mathbf n^\\top \\langle\\boldsymbol\\lambda\\rangle + \\tfrac 1 2 \\left \\{ \\operatorname{tr}[\\boldsymbol\\Sigma_0^{-1}\\boldsymbol\\Sigma] - \\ln|\\boldsymbol\\Sigma|\\right\\}\n",
    "\\\\\n",
    "\\langle\\boldsymbol\\lambda\\rangle &= \n",
    "\\exp\\left(\\boldsymbol\\mu + \\tfrac 1 2 \\operatorname{diag}[\\boldsymbol\\Sigma]\\right)\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d377d2d-6788-4ffe-8754-295cd33cbbf9",
   "metadata": {},
   "source": [
    "Using the formula from The Matrix Cookbook, the derivative of this in $\\boldsymbol\\Sigma$ (Jacobian) is \n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Sigma}\\mathcal L\n",
    "&=\n",
    "\\tfrac 1 2\\left\\{\\operatorname{diag}[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle]+ \\boldsymbol\\Sigma_0^{-1}- \\boldsymbol\\Sigma^{-1}\\right\\}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46622229-e7e4-4148-a4a8-53860836e39b",
   "metadata": {},
   "source": [
    "Ideally, we also want to get the second derivative, since Newton-Raphson (often) provides quadratic convergence. The Hessian is a fourth-order tensor, wich is cumbersome. However, we only need to compute Hessian-vector products. These can be calculated by taking the derivative of the Jacobian times a \"vector\". In this case, since the object being optimized is a matrix, we take the scalar product between the Matrix-valued Jacobian and a matrix. \n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\left<\\operatorname H_{\\boldsymbol\\Sigma} \\mathcal L,\\mathbf M\\right>\n",
    "&=\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Sigma} \n",
    "\\left<\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Sigma}\\mathcal L\n",
    ",\\mathbf M\n",
    "\\right>\n",
    "\\\\&=\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Sigma}\n",
    "\\operatorname{tr}\\left[\n",
    "\\left(\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Sigma}\\mathcal L\n",
    "\\right)^\\top\n",
    "\\mathbf M\n",
    "\\right]\n",
    "\\\\\n",
    "&=\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Sigma}\n",
    "\\operatorname{tr}\\left[\n",
    "\\left(\n",
    "\\tfrac 1 2\\left\\{\\operatorname{diag}[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle]\n",
    "+ \\boldsymbol\\Sigma_0^{-1}- \\boldsymbol\\Sigma^{-1}\\right\\}\n",
    "\\right)^\\top\n",
    "\\mathbf M\n",
    "\\right]\n",
    "\\\\\n",
    "&=\n",
    "\\tfrac 1 2 \n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Sigma}\n",
    "\\operatorname{tr}\\left[\n",
    "\\left(\n",
    "\\operatorname{diag}[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle ]\n",
    "+ \\boldsymbol\\Sigma_0^{-1}- \\boldsymbol\\Sigma^{-1}\n",
    "\\right)\n",
    "\\mathbf M\n",
    "\\right]\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "(transposes are dropped in the final step because $\\operatorname{diag}[\\cdot]$ and $\\boldsymbol\\Sigma_0$ are symmetric). Using the formula in The Matrix Cookbook, we can evaluate these trace derivatives. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76f8c79-246d-496e-becb-21f012a8e4e7",
   "metadata": {},
   "source": [
    "\\begin{equation}\\begin{aligned}\n",
    "\\left<\\operatorname H_{\\boldsymbol\\Sigma} \\mathcal L,\\mathbf M\\right>\n",
    "&=\n",
    "\\tfrac 1 2 \n",
    "\\left\\{\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Sigma}\n",
    "\\operatorname{tr}\\left[\n",
    "\\left(\n",
    "\\operatorname{diag}[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle ]\n",
    "- \\boldsymbol\\Sigma^{-1}\n",
    "\\right)\n",
    "\\mathbf M\n",
    "\\right]\n",
    "\\right\\}\n",
    "\\\\\n",
    "&=\n",
    "\\tfrac 1 2 \n",
    "\\left\\{\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Sigma}\n",
    "\\operatorname{tr}\\left[\n",
    "\\operatorname{diag}[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle ]\n",
    "\\mathbf M\n",
    "\\right]\n",
    "-\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Sigma}\n",
    "\\operatorname{tr}\\left[\n",
    "\\boldsymbol\\Sigma^{-1}\n",
    "\\mathbf M\n",
    "\\right]\n",
    "\\right\\}\n",
    "\\\\\n",
    "&=\n",
    "\\tfrac 1 2 \n",
    "\\left\\{\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Sigma}\n",
    "\\operatorname{tr}\\left[\n",
    "\\operatorname{diag}[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle ]\n",
    "\\mathbf M\n",
    "\\right]\n",
    "+\n",
    "\\boldsymbol\\Sigma^{-1}\n",
    "\\mathbf M^\\top\n",
    "\\boldsymbol\\Sigma^{-1}\n",
    "\\right\\}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190a98f5-30f7-40bf-bf14-1f5cb8dd83bf",
   "metadata": {},
   "source": [
    "The derivative of the trace of a matrix-valued function is the transpose of the scalar-derivative of said function. $\\operatorname{\\nabla}_{\\boldsymbol\\Sigma}\n",
    "\\operatorname{tr}\\left[\n",
    "\\operatorname{diag}[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle ]\n",
    "\\mathbf M\n",
    "\\right]$ is best computed element-wise:\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Sigma}\n",
    "\\operatorname{tr}\\left[\n",
    "\\operatorname{diag}[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle ]\\,\n",
    "\\mathbf M\n",
    "\\right]\n",
    "&= \n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Sigma}\n",
    "\\sum_k\n",
    "[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle]_k\n",
    "\\mathbf M_{k}\n",
    "\\\\\n",
    "&= \n",
    "\\sum_k\n",
    "n_k \\mathbf M_{k} \\operatorname{\\nabla}_{\\boldsymbol\\Sigma} \\langle\\lambda_k\\rangle\n",
    "\\\\\n",
    "&=\n",
    "\\tfrac 1 2 \\operatorname{diag}\\left[\n",
    "\\mathbf n\\circ\\boldsymbol\\lambda\\circ\\operatorname{diag}(\\mathbf M)\n",
    "\\right]\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d56b9e-f2fe-4591-9489-d775d4755210",
   "metadata": {},
   "source": [
    "\\begin{equation}\\begin{aligned}\n",
    "\\left<\\operatorname H_{\\boldsymbol\\Sigma} \\mathcal L,\\mathbf M\\right>\n",
    "&=\n",
    "\\tfrac 1 2 \n",
    "\\left\\{\n",
    "\\tfrac 1 2 \\operatorname{diag}\\left[\n",
    "\\mathbf n\\circ\\boldsymbol\\lambda\\circ\\operatorname{diag}(\\mathbf M)\n",
    "\\right]\n",
    "+\n",
    "\\boldsymbol\\Sigma^{-1}\n",
    "\\mathbf M^\\top\n",
    "\\boldsymbol\\Sigma^{-1}\n",
    "\\right\\}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b39969-2365-44cf-aaf9-e4e7a3b98123",
   "metadata": {},
   "source": [
    "## Numerically verify these gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc2ace1-af8d-419c-aa66-319e1ba7fa26",
   "metadata": {},
   "source": [
    "## Gradients of parameterized posterior covariance\n",
    "\n",
    "The above gradients only apply if we're parameterizing $\\boldsymbol\\Sigma$ directly. This is computationally impractical. We explore the following: \n",
    "\n",
    "1. $\\boldsymbol\\Sigma = \\mathbf A\\operatorname{diag}[\\mathbf v]\\,\\mathbf A^\\top$\n",
    "2. $\\boldsymbol\\Sigma = \\mathbf X \\mathbf X^\\top$\n",
    "3. $\\boldsymbol\\Sigma = \\mathbf F^\\top \\mathbf Q\\mathbf Q^\\top \\mathbf F$\n",
    "4. $\\boldsymbol\\Sigma = \\left(\\boldsymbol\\Sigma_0^{-1}+\\operatorname{diag}[\\mathbf p]\\right)^{-1}$\n",
    "\n",
    "How can we handle these derivatives? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097eed39-8900-47d9-812f-1e98892a4042",
   "metadata": {},
   "source": [
    "In cases (2) and (3), $\\boldsymbol\\Sigma$ isn't full rank, and the term $\\ln|\\boldsymbol\\Sigma|$ diverges to negative infinity. However, since the null space of $\\boldsymbol\\Sigma$ is not being optimized, it does not affect the gradient. Since $\\boldsymbol\\Sigma$ is positive semi-definite, it can always be factored as:\n",
    "\n",
    "$$\n",
    "\\boldsymbol\\Sigma = \\mathbf X\\mathbf X^\\top\n",
    "$$\n",
    "\n",
    "In these cases, the log-determinant can be replaced by $\\ln|\\mathbf X^\\top\\mathbf X|$, which remains well-defined assuming $\\mathbf X$ has fixed rank $\\mathbf K$ euqal to its number of columns. The derivative of this expression in $\\mathbf X$ is:\n",
    "\n",
    "$$\n",
    "\\partial_{\\mathbf X} \\ln |\\mathbf X^\\top\\mathbf X| = 2 {\\mathbf X^+}^\\top\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee8a7ba-dca7-45ae-9840-8d6c2f121c51",
   "metadata": {},
   "source": [
    "\\begin{equation}\\begin{aligned}\n",
    "\\partial_{\\mathbf X_{ij}}\\boldsymbol\\Sigma_{kl} \n",
    "&= \n",
    "\\sum_m \n",
    "\\partial_{\\mathbf X_{ij}}\n",
    "\\mathbf X_{km} \\mathbf X_{lm}\n",
    "\\\\\n",
    "&=\n",
    "\\sum_m \n",
    "\\delta_{ij=km} \\mathbf X_{lm}\n",
    "+\n",
    "\\mathbf X_{km} \\delta_{ij=lm}\n",
    "\\\\\n",
    "&=\n",
    "\\delta_{i=k} \\mathbf X_{lj}\n",
    "+\n",
    "\\mathbf X_{kj} \\delta_{i=l}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638448f8-827b-4c2a-865f-3aa68569c97c",
   "metadata": {},
   "source": [
    "According to The Matrix Cookbook, if $\\boldsymbol\\Sigma(\\theta_i)$ is a function of a parameter $\\theta_i$, then the chain rule is: \n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\frac{\\partial\\mathcal L}{\\partial\\theta_i} = \n",
    "\\left<\n",
    "\\frac{\\partial\\mathcal L}{\\partial\\boldsymbol\\Sigma}\n",
    ",\n",
    "\\frac{\\partial\\boldsymbol\\Sigma}{\\partial \\theta_i}\n",
    "\\right>\n",
    "=\n",
    "\\operatorname{tr}\\left[\n",
    "\\left(\\frac{\\partial\\mathcal L}{\\partial\\boldsymbol\\Sigma}\n",
    "\\right)^\\top\n",
    "\\frac{\\partial\\boldsymbol\\Sigma}{\\partial \\theta_i}\n",
    "\\right]\n",
    "=\n",
    "\\sum_{kl}\n",
    "\\frac{\\partial\\mathcal L}{\\partial\\boldsymbol\\Sigma_{kl}}\n",
    "\\frac{\\partial\\boldsymbol\\Sigma_{kl}}{\\partial \\theta_i}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e062a2-f21a-48b4-98b2-0fb8c21d51bc",
   "metadata": {},
   "source": [
    "For a vector or matrix of parameters $\\boldsymbol\\Theta$, we write this succinctly as \n",
    "\n",
    "$$\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Theta} \\mathcal L\n",
    "=\n",
    "\\left<\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Sigma} \\mathcal L\n",
    ",\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Theta} \\boldsymbol\\Sigma\n",
    "\\right>\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83362e98-4f69-4616-a044-e25f7c8374b0",
   "metadata": {},
   "source": [
    "$$\n",
    "\\left<\n",
    "\\frac{\\partial\\mathcal L}{\\partial\\boldsymbol\\Theta}\n",
    ",\n",
    "\\mathbf U\n",
    "\\right>\n",
    "=\n",
    "\\left<\n",
    "\\left<\n",
    "\\frac{\\partial\\mathcal L}{\\partial\\boldsymbol\\Sigma}\n",
    ",\n",
    "\\frac{\\partial\\boldsymbol\\Sigma}{\\partial\\boldsymbol\\Theta}\n",
    "\\right>\n",
    ",\n",
    "\\mathbf U\n",
    "\\right>\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c561c53d-ee7e-4389-aca0-8bccd7a864cb",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial\\mathcal L}{\\partial\\boldsymbol\\Theta^\\top}\n",
    "\\left<\n",
    "\\frac{\\partial\\mathcal L}{\\partial\\boldsymbol\\Theta}\n",
    ",\n",
    "\\mathbf M\n",
    "\\right>\n",
    "=\n",
    "\\frac{\\partial\\mathcal L}{\\partial\\boldsymbol\\Theta^\\top}\n",
    "\\left<\n",
    "\\left<\n",
    "\\frac{\\partial\\mathcal L}{\\partial\\boldsymbol\\Sigma}\n",
    ",\n",
    "\\frac{\\partial\\boldsymbol\\Sigma}{\\partial\\boldsymbol\\Theta}\n",
    "\\right>\n",
    ",\n",
    "\\mathbf M\n",
    "\\right>\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8a9d43-4d6a-4b7d-88db-bd6a524be8e9",
   "metadata": {},
   "source": [
    "The chain rule applies to the Hessian-vector product as follows: \n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\left<\\operatorname H_{\\boldsymbol\\Sigma} \\mathcal L,\\mathbf M\\right>\n",
    "&=\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Sigma} \n",
    "\\left<\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Sigma}\\mathcal L\n",
    ",\\mathbf M\n",
    "\\right>\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb36fe9-5e56-40fd-9258-277c348bb6ad",
   "metadata": {},
   "source": [
    "\\begin{equation}\\begin{aligned}\n",
    "\\left<\\operatorname{H}_{\\boldsymbol\\Theta}\\mathcal L,\\mathbf M\\right>\n",
    "&=\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Theta}\n",
    "\\left<\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Theta} \\mathcal L,\n",
    "\\mathbf M\n",
    "\\right>\n",
    "\\\\&=\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Theta}\\left<\\left<\\operatorname{\\nabla}_{\\boldsymbol\\Sigma} \\mathcal L,\\operatorname{\\nabla}_{\\boldsymbol\\Theta} \\boldsymbol\\Sigma\\right>,\\mathbf M\\right>\n",
    "\\\\\n",
    "&=\n",
    "\\left<\\operatorname{\\nabla}_{\\boldsymbol\\theta} \\boldsymbol\\Sigma,\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Sigma}\\left<\\left<\\operatorname{\\nabla}_{\\boldsymbol\\Sigma} \\mathcal L,\\operatorname{\\nabla}_{\\boldsymbol\\Theta} \\boldsymbol\\Sigma\\right>,\\mathbf M\\right>\\right>\n",
    "\\\\\n",
    "&=\n",
    "\\left<\n",
    "\\left<\n",
    "\\left<\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Theta} \\boldsymbol\\Sigma\n",
    ",\n",
    "\\operatorname{H}_{\\boldsymbol\\Sigma} \\mathcal L\n",
    "\\right>\n",
    ",\n",
    "\\mathbf M\n",
    "\\right>\n",
    ",\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\theta} \\boldsymbol\\Sigma\n",
    "\\right>\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc697ee6-8890-43d5-97ab-312432be1e34",
   "metadata": {},
   "source": [
    "Assuming everything is associative this might mean something: \n",
    "    \n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\left<\\operatorname{H}_{\\boldsymbol\\Theta}\\mathcal L,\\mathbf M\\right>\n",
    "&=\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Theta} \\boldsymbol\\Sigma\n",
    ":\n",
    "\\operatorname{H}_{\\boldsymbol\\Sigma} \\mathcal L\n",
    ":\n",
    "\\mathbf M\n",
    ":\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\theta} \\boldsymbol\\Sigma\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\left<\\operatorname{H}_{\\boldsymbol\\Theta}\\mathcal L,\\mathbf M\\right>\n",
    "&=\n",
    "[\\operatorname{\\nabla}_{\\boldsymbol\\Theta} \\boldsymbol\\Sigma]\n",
    "[\\operatorname{H}_{\\boldsymbol\\Sigma} \\mathcal L](\\mathbf M)\n",
    "[\\operatorname{\\nabla}_{\\boldsymbol\\theta} \\boldsymbol\\Sigma]^\\top\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7553a4-1618-4f46-92ba-a61b767191a1",
   "metadata": {},
   "source": [
    "# Cleaning up this mess\n",
    "\n",
    "The original Jacobian and Hessian-vector product are\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Sigma}\\mathcal L\n",
    "&=\n",
    "\\tfrac 1 2\\left\\{\\operatorname{diag}[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle]+ \\boldsymbol\\Sigma_0^{-1}- \\boldsymbol\\Sigma^{-1}\\right\\}\n",
    "\\\\\n",
    "\\left<\\operatorname H_{\\boldsymbol\\Sigma} \\mathcal L,\\mathbf M\\right>\n",
    "&=\n",
    "\\tfrac 1 2 \n",
    "\\left\\{\n",
    "\\tfrac 1 2 \\operatorname{diag}\\left[\n",
    "\\mathbf n\\circ\\boldsymbol\\lambda\\circ\\operatorname{diag}(\\mathbf M)\n",
    "\\right]\n",
    "+\n",
    "\\boldsymbol\\Sigma^{-1}\n",
    "\\mathbf M^\\top\n",
    "\\boldsymbol\\Sigma^{-1}\n",
    "\\right\\}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37160f67-3504-4928-bb57-cb98bfbfda18",
   "metadata": {},
   "source": [
    "The chain rule for the Jacobian and Hessian-vector product are: \n",
    "\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Theta} \\mathcal L\n",
    "&=\n",
    "\\left<\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Theta} \\boldsymbol\\Sigma,\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Sigma} \\mathcal L\n",
    "\\right>\n",
    "\\\\\n",
    "\\left<\\operatorname{H}_{\\boldsymbol\\Theta}\\mathcal L,\\mathbf U\\right>\n",
    "&=\n",
    "\\left<\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Theta}\\boldsymbol\\Sigma\n",
    ",\n",
    "\\left<\n",
    "\\operatorname H_{\\boldsymbol\\Sigma}\\mathcal L\n",
    ",\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Theta}\\boldsymbol\\Sigma\n",
    "\\right>\n",
    ",\n",
    "\\mathbf U\n",
    "\\right>\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9a50f2-c3f4-456c-8b18-4ba409c0c108",
   "metadata": {},
   "source": [
    "For each parameterization, we need to write down $\\operatorname{\\nabla}_{\\boldsymbol\\Theta} \\boldsymbol\\Sigma$, if possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fc266e-88d5-4784-8fc8-f3906f41eb42",
   "metadata": {},
   "source": [
    "$H$ is a binlinear form that accepts matrices $M$. \n",
    "\n",
    "$\\operatorname{\\nabla}_{\\boldsymbol\\Theta} \\boldsymbol\\Sigma$ is also a bilinear form. It relates matrix-valued derivatives in $\\boldsymbol\\Sigma$ to matrix-valued derivatives in $\\boldsymbol\\Theta$. \n",
    "\n",
    "$\\operatorname{\\nabla}_{\\boldsymbol\\Theta} \\boldsymbol\\Sigma$ is typically not invertable. But it may not matter, pseudoinverse is OK, if available. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d744bf03-dac8-4a81-ad2e-d20dec5cce6d",
   "metadata": {},
   "source": [
    "\n",
    "1. $\\boldsymbol\\Sigma = \\mathbf A\\operatorname{diag}[\\mathbf v]\\,\\mathbf A^\\top$\n",
    "2. $\\boldsymbol\\Sigma = \\mathbf X \\mathbf X^\\top$\n",
    "3. $\\boldsymbol\\Sigma = \\mathbf F^\\top \\mathbf Q\\mathbf Q^\\top \\mathbf F$\n",
    "4. $\\boldsymbol\\Sigma = \\left(\\boldsymbol\\Sigma_0^{-1}+\\operatorname{diag}[\\mathbf p]\\right)^{-1}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010c59e9-3dbe-4f00-9f8b-daa99f6b7c7e",
   "metadata": {},
   "source": [
    "### $\\boldsymbol\\Sigma = \\mathbf A\\operatorname{diag}[\\mathbf v]\\,\\mathbf A^\\top$\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\partial_{\\mathbf v_k}\\boldsymbol\\Sigma_{ij}\n",
    "&= \n",
    "\\sum_{lm} \n",
    "\\partial_{\\mathbf v_k}\n",
    "\\mathbf A_{il}\n",
    "\\operatorname{diag}[\\mathbf v]_{lm}\n",
    "\\mathbf A^\\top_{mj}\n",
    "\\\\\n",
    "&= \n",
    "\\sum_{l} \n",
    "\\partial_{\\mathbf v_k}\n",
    "\\mathbf A_{il}\n",
    "\\mathbf v_l\n",
    "\\mathbf A^\\top_{lj}\n",
    "\\\\\n",
    "&= \n",
    "\\mathbf A_{ik}\n",
    "\\mathbf v_k\n",
    "\\mathbf A^\\top_{kj}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9be312b-2a8e-464b-92d1-3f72c40b61ed",
   "metadata": {},
   "source": [
    "This operates on $\\mathbf v$ (index $k$) and $\\mathbf \\Sigma$ (indecies $ij$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3538de00-4b5f-442c-add8-0a0aed197a61",
   "metadata": {},
   "source": [
    "\\begin{equation}\\begin{aligned}\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Sigma}\\mathcal L\n",
    "&=\n",
    "\\tfrac 1 2\\left\\{\\operatorname{diag}[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle]+ \\boldsymbol\\Sigma_0^{-1}- \\boldsymbol\\Sigma^{-1}\\right\\}\n",
    "\\\\\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Theta} \\mathcal L\n",
    "&=\n",
    "\\left<\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Theta} \\boldsymbol\\Sigma,\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Sigma} \\mathcal L\n",
    "\\right>\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fbacfe-a30c-478c-afcc-03fb8cd2c258",
   "metadata": {},
   "source": [
    "\\begin{equation}\\begin{aligned}\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Sigma}\\mathcal L\n",
    "&=\n",
    "\\tfrac 1 2\\left\\{\\operatorname{diag}[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle]+ \\boldsymbol\\Sigma_0^{-1}- \\boldsymbol\\Sigma^{-1}\\right\\}\n",
    "\\\\\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Theta} \\mathcal L\n",
    "&=\n",
    "\\left<\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Theta} \\boldsymbol\\Sigma,\n",
    "\\operatorname{\\nabla}_{\\boldsymbol\\Sigma} \\mathcal L\n",
    "\\right>\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe14d5a-7993-45de-b407-ac2c06a22197",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\frac{\\partial\\mathcal L}{\\partial\\theta_i} = \n",
    "\\left<\n",
    "\\frac{\\partial\\mathcal L}{\\partial\\boldsymbol\\Sigma}\n",
    ",\n",
    "\\frac{\\partial\\boldsymbol\\Sigma}{\\partial \\theta_i}\n",
    "\\right>\n",
    "=\n",
    "\\operatorname{tr}\\left[\n",
    "\\left(\\frac{\\partial\\mathcal L}{\\partial\\boldsymbol\\Sigma}\n",
    "\\right)^\\top\n",
    "\\frac{\\partial\\boldsymbol\\Sigma}{\\partial \\theta_i}\n",
    "\\right]\n",
    "=\n",
    "\\sum_{kl}\n",
    "\\frac{\\partial\\mathcal L}{\\partial\\boldsymbol\\Sigma_{kl}}\n",
    "\\frac{\\partial\\boldsymbol\\Sigma_{kl}}{\\partial \\theta_i}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a3e5db-b611-4d02-a435-646206cb024c",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\sum_{ij}\n",
    "\\frac{\\partial\\mathcal L}{\\partial\\boldsymbol\\Sigma_{ij}}\n",
    "\\frac{\\partial\\boldsymbol\\Sigma_{ij}}{\\partial \\mathbf v_k}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b576af7b-b6af-4054-a7a7-954a93638aeb",
   "metadata": {},
   "source": [
    "\\begin{equation}\\begin{aligned}\n",
    "\\sum_{ij}\n",
    "\\frac{\\partial\\mathcal L}{\\partial\\boldsymbol\\Sigma_{ij}}\n",
    "\\mathbf A_{ik}\n",
    "\\mathbf v_k\n",
    "\\mathbf A^\\top_{kj}\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\sum_{ij}\n",
    "\\tfrac 1 2\\left\\{\\operatorname{diag}[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle]+ \\boldsymbol\\Sigma_0^{-1}- \\boldsymbol\\Sigma^{-1}\\right\\}_{ij}\n",
    "\\mathbf A_{ik}\n",
    "\\mathbf v_k\n",
    "\\mathbf A^\\top_{kj}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9794aa47-7b9d-4c2a-b314-9797bf538177",
   "metadata": {},
   "source": [
    "\\begin{equation}\\begin{aligned}\n",
    "\\tfrac 1 2\\left\\{\n",
    "\\sum_{ij}\n",
    "\\operatorname{diag}[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle]_{ij}\n",
    "\\mathbf A_{ik}\n",
    "\\mathbf v_k\n",
    "\\mathbf A^\\top_{kj}\n",
    "+ \n",
    "\\sum_{ij}\n",
    "{\\boldsymbol\\Sigma_0^{-1}}_{ij}\n",
    "\\mathbf A_{ik}\n",
    "\\mathbf v_k\n",
    "\\mathbf A^\\top_{kj}\n",
    "- \n",
    "\\sum_{ij}\n",
    "\\boldsymbol\\Sigma^{-1}_{ij}\n",
    "\\mathbf A_{ik}\n",
    "\\mathbf v_k\n",
    "\\mathbf A^\\top_{kj}\n",
    "\\right\\}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e9908f-bdc2-4cd8-99db-3f8be99be184",
   "metadata": {},
   "source": [
    "\\begin{equation}\\begin{aligned}\n",
    "\\tfrac 1 2\n",
    "v_k\n",
    "\\left\\{\n",
    "[\\mathbf A^\\top\n",
    "\\operatorname{diag}[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle]\n",
    "\\mathbf A]_{kk}\n",
    "+ \n",
    "[A^\\top Î£_0^{-1} A]_{kk}\n",
    "- \n",
    "[A^\\top Î£ A]_{kk}\n",
    "\\right\\}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c955fa90-038b-451e-b4e8-36e515ec3d1b",
   "metadata": {},
   "source": [
    "$\n",
    "\\boldsymbol\\Sigma^{-1} = [\\mathbf A\\operatorname{diag}[\\mathbf v]\\,\\mathbf A^\\top]^{-1}\n",
    "=\n",
    "\\mathbf A\\operatorname{diag}[\\mathbf v^{-1}]\\,\\mathbf A^{-1}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c15ddc2-2ac7-47f4-9fc3-7ec1e9875cfe",
   "metadata": {},
   "source": [
    "$$\n",
    "dg[Î£]_i = Î£_{ii} = A_{ij}^2 v_j\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8fc4d1-0798-4d93-a609-0e51f59bb836",
   "metadata": {},
   "source": [
    "\\begin{equation}\\begin{aligned}\n",
    "%%%% GRADIENT IN v\n",
    "\\operatorname{\\nabla}_{\\mathbf v}\n",
    "\\mathcal L &=\\tfrac 1 2 \\left\\{\n",
    "\\mathbf G^\\top (\\mathbf n \\circ \\langle\\boldsymbol\\lambda\\rangle)\n",
    "+ \\operatorname{diag}[\\mathbf A \\boldsymbol\\Sigma_0^{-1} \\mathbf A^\\top]\n",
    "- \\tfrac 1 {\\mathbf v}\n",
    "\\right\\}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267d871c-398c-4543-b8cd-2bf813465d1a",
   "metadata": {},
   "source": [
    "The gradient and Hessian of this loss function in $\\mathbf v$ are : \n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "%%%% GRADIENT IN v\n",
    "\\operatorname{\\nabla}_{\\mathbf v}\n",
    "\\mathcal L &=\\tfrac 1 2 \\left\\{\n",
    "\\mathbf G^\\top (\\mathbf n \\circ \\langle\\boldsymbol\\lambda\\rangle)\n",
    "+ \\operatorname{diag}[\\mathbf A \\boldsymbol\\Sigma_0^{-1} \\mathbf A^\\top]\n",
    "- \\tfrac 1 {\\mathbf v}\n",
    "\\right\\}\n",
    "\\\\\n",
    "%%%% HESSIAN IN v\n",
    "\\operatorname{H}_{\\mathbf v}\n",
    "\\mathcal L &=\\tfrac 1 2 \\left\\{\n",
    "\\tfrac 1 2 \n",
    "\\mathbf G \\operatorname{diag}[\\mathbf n \\circ \\langle\\boldsymbol\\lambda\\rangle] \\, \\mathbf G \n",
    "+ \\operatorname{diag}\\left[\\tfrac 1 {\\mathbf v^2}\\right]\n",
    "\\right\\}\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "This follows from the usual matrix and scalar derivatives, with the exception of the term $\\mathbf n^\\top \\langle\\boldsymbol\\lambda\\rangle$. These can be obtained by considering the derivative with respect to single elements of $\\mathbf v$ (note: $\\mathbf G$ is symmetric): \n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\tfrac{d}{dv_j} \\mathbf n^\\top\\langle\\boldsymbol\\lambda\\rangle \n",
    "&=  \\mathbf n^\\top\n",
    "\\tfrac{d}{dv_j}  \\langle\\boldsymbol\\lambda\\rangle \n",
    "\\\\\n",
    "&=  \\mathbf n^\\top\n",
    "\\tfrac{d}{dv_j} \\exp\\left(\\boldsymbol\\mu + \\tfrac12\\mathbf G\\mathbf v\\right)\n",
    "\\\\\n",
    "&= \\tfrac{d}{dv_j} \\sum_k\n",
    "n_k \\exp\\left[\\mu_k + \\tfrac12(\\mathbf G\\mathbf v)_k\\right]\n",
    "\\\\\n",
    "&= \\sum_k\n",
    "n_k \\left[\n",
    "\\langle\\lambda_k\\rangle\n",
    "\\cdot \\tfrac12 \\tfrac{d}{dv_j} (\\mathbf G\\mathbf v)_k\n",
    "\\right]\n",
    "\\\\\n",
    "&= \n",
    "\\tfrac12 \\sum_k\n",
    " n_k \n",
    "\\langle\\boldsymbol\\lambda_k\\rangle\n",
    "\\textstyle \\mathbf G_{kj} \n",
    "\\\\\n",
    "&= \n",
    "\\tfrac12 \\left[ \\mathbf G^\\top(\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle) \\right]_j\n",
    "\\\\\\\\\n",
    "\\tfrac{d^2}{dv_iv_j} \\mathbf n^\\top\\langle\\boldsymbol\\lambda\\rangle \n",
    "&= \n",
    "\\tfrac12 \\left[ \\sum_k n_k \\tfrac{d}{dv_i} \\langle\\boldsymbol\\lambda_k\\rangle\\textstyle \\mathbf G_{kj} \\right]_j\n",
    "\\\\\n",
    "&= \n",
    "\\tfrac14 \\left[ \\sum_k n_k \n",
    "\\langle\\boldsymbol\\lambda_k\\rangle\n",
    "\\textstyle \\mathbf G_{jk} \n",
    "\\textstyle \\mathbf G_{ki} \n",
    "\\right]_j\n",
    "\\\\\n",
    "&= \n",
    "\\tfrac 1 4 \\left[\\mathbf G \\operatorname{diag}[\\mathbf n\\circ \\langle\\boldsymbol\\lambda\\rangle] \\, \n",
    "\\mathbf G\n",
    "\\right]_{ij}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babdb9cb-510f-4a14-b188-3e7a3e1ba9be",
   "metadata": {},
   "source": [
    "## Low-rank approximation $\\boldsymbol\\Sigma = \\mathbf X \\mathbf X^\\top$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15511d32-11c4-470b-b92c-16500a37eaf8",
   "metadata": {},
   "source": [
    "We consider an approximate posterior covariance of the form\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\boldsymbol\\Sigma^{-1} &\\approx \\mathbf X \\mathbf X^\\top,\\,\\,\\,\\,\\mathbf X\\in\\mathbb R^{L^2\\times K}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d744358-14df-4275-85c2-f1a46febcd7d",
   "metadata": {},
   "source": [
    "where $\\mathbf X$ is a tall, thin matrix, with as many rows as there are spatial bins ($L^2$), and $K<L^2$ columns. We view $\\mathbf X$ as being composed of $L^2$ length-$K$ row-vectors $\\mathbf x_k$. \n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\mathbf X^\\top &= \\{ \\mathbf x_1^\\top,...,\\mathbf x_{L^2}^\\top \\}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a66793-cbe8-4ff8-80d1-d7a5da734ab2",
   "metadata": {},
   "source": [
    "Neglecting terms that do not depend on $\\mathbf X$, the loss to be minimized is:\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\mathcal L(\\mathbf X)&=\\mathbf n^\\top \\exp\\left(\\boldsymbol\\mu + \\tfrac 1 2 \\operatorname{diag}\\left[\\mathbf X \\mathbf X^\\top\\right]\\right)+ \\tfrac 1 2 \\left \\{ \\operatorname{tr}\\left[\\boldsymbol\\Sigma_0^{-1}\\mathbf X \\mathbf X^\\top\\right] - \\ln|\\mathbf X^\\top \\mathbf X |\\right\\}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27564ff7-f5f8-4907-9be8-7e629ae5507f",
   "metadata": {},
   "source": [
    "Note that we have used $\\ln|\\mathbf X^\\top \\mathbf X |$ above, rather than $\\ln|\\mathbf X\\mathbf X^\\top|$\n",
    "Since $\\mathbf X \\mathbf X^\\top$ is rank $K<L^2$, it always as a subspace of size $L^2-K$ with zero eigenvalues. This null space doesn't affect the gradient, but it does make the log-determinant undefined. $\\ln|\\mathbf X^\\top \\mathbf X |$ considers only the log-determinant in the low-rank space spanned by $\\mathbf X$, and remains finite. The Jacobian is:\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\operatorname{\\nabla}_{\\mathbf X}\n",
    "\\mathcal L &=\n",
    "\\left(\n",
    "\\operatorname{diag}\\left[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle\\right] + \\boldsymbol\\Sigma_0^{-1}\\right)\\mathbf X - {\\mathbf X^{+}}^\\top\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "\n",
    "The derivatives of $\\operatorname{tr}\\left[\\boldsymbol\\Sigma_0^{-1}\\mathbf X \\mathbf X^\\top\\right]$ and $\\ln|\\mathbf X \\mathbf X^\\top|$ can be found in The Matrix Cookbook. The gradient of $\\mathbf n^\\top \\exp\\left(\\boldsymbol\\mu+ \\tfrac 1 2 \\operatorname{diag}\\left[\\mathbf X \\mathbf X^\\top\\right]\\right)$ can be solved by considering single elements of $\\mathbf X$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a828c9-895c-446d-b697-b057ae253e72",
   "metadata": {},
   "source": [
    "\\begin{equation}\\begin{aligned}\n",
    "\\tfrac{d}{dx_{ij}}\n",
    "\\mathbf n^\\top \\exp\\left(\\boldsymbol\\mu+ \\tfrac 1 2 \\operatorname{diag}\\left[\\mathbf X \\mathbf X^\\top\\right]\\right)\n",
    "&=\n",
    "\\textstyle\\sum_l n_l\\langle\\lambda_l\\rangle\n",
    "\\tfrac12 \\tfrac{d}{dx_{ij}} \\operatorname{diag}\\left[\\mathbf X \\mathbf X^\\top\\right]_l\n",
    "\\\\&=\n",
    "\\textstyle\\sum_l n_l\\langle\\lambda_l\\rangle\n",
    "\\tfrac12\\sum_k \\tfrac{d}{dx_{ij}} \\mathbf x_{lk}^2\n",
    "\\\\&=\n",
    "\\textstyle\\sum_l n_l\\langle\\lambda_l\\rangle\n",
    "\\tfrac12\\sum_k 2 \\mathbf x_{lk} \\delta_{ij=lk}\n",
    "\\\\&=\n",
    "\\textstyle\\sum_l n_l\\langle\\lambda_l\\rangle\n",
    "\\mathbf x_{lj} \\delta_{i=l}\n",
    "\\\\&=\n",
    "n_i\\langle\\lambda_i\\rangle \\mathbf x_{ij}\n",
    "\\\\&=\n",
    "\\left[\\operatorname{diag}[\\mathbf n\\circ \\langle\\boldsymbol\\lambda\\rangle]\\, \\mathbf X\\right]_{ij}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddeac11-82ad-451d-8832-5f6bdefea242",
   "metadata": {},
   "source": [
    "\\begin{equation}\\begin{aligned}\n",
    "\\operatorname{\\partial}_{\\mathbf X_{ij}} \n",
    "\\left< \n",
    "\\operatorname{diag}\\left[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle\\right] \\mathbf X\n",
    ", \n",
    "\\mathbf M \n",
    "\\right>\n",
    "&\n",
    "=\n",
    "\\operatorname{\\partial}_{\\mathbf X_{ij}} \n",
    "\\operatorname{tr}\\left[\n",
    "\\mathbf X^\\top \\operatorname{diag}\\left[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle\\right] \n",
    "\\mathbf M\n",
    "\\right]\n",
    "\\\\\n",
    "&\n",
    "=\n",
    "\\operatorname{\\partial}_{\\mathbf X_{ij}}\n",
    "\\textstyle\\sum_k\n",
    "\\left[\n",
    "\\mathbf X^\\top \\operatorname{diag}\\left[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle\\right] \n",
    "\\mathbf M\n",
    "\\right]_kk\n",
    "\\\\\n",
    "&\n",
    "=\n",
    "\\operatorname{\\partial}_{\\mathbf X_{ij}}\n",
    "\\textstyle\\sum_{klm}\n",
    "\\mathbf X^\\top_{kl} \\operatorname{diag}\\left[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle\\right]_{lm}\n",
    "\\mathbf M_{mk}\n",
    "\\\\\n",
    "&\n",
    "=\n",
    "\\operatorname{\\partial}_{\\mathbf X_{ij}}\n",
    "\\textstyle\\sum_{kl}\n",
    "\\left(\n",
    "\\mathbf X_{lk} \\left[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle\\right]_{l}\n",
    "\\right)\n",
    "\\mathbf M_{lk}\n",
    "\\\\\n",
    "&\n",
    "=\n",
    "\\operatorname{\\partial}_{\\mathbf X_{ij}}\n",
    "\\textstyle\\sum_{kl}\n",
    "\\left(\n",
    "\\mathbf X_{lk} n_l\\langle\\lambda_l\\rangle\n",
    "\\right)\n",
    "\\mathbf M_{lk}\n",
    "\\\\\n",
    "&\n",
    "=\n",
    "\\textstyle\\sum_{kl}\n",
    "\\left[\n",
    "\\left(\n",
    "\\operatorname{\\partial}_{\\mathbf X_{ij}}\n",
    "\\mathbf X_{lk} \n",
    "\\right)\n",
    "n_l\\langle\\lambda_l\\rangle\n",
    "+\n",
    "\\mathbf X_{lk} \n",
    "\\left(\n",
    "\\operatorname{\\partial}_{\\mathbf X_{ij}}\n",
    "n_l\\langle\\lambda_l\\rangle\n",
    "\\right)\n",
    "\\right]\n",
    "\\mathbf M_{lk}\n",
    "\\\\\n",
    "&\n",
    "=\n",
    "\\textstyle\\sum_{kl}\n",
    "\\left[\n",
    "\\delta_{il} \\delta_{jk} n_l\\langle\\lambda_l\\rangle\n",
    "+\n",
    "\\mathbf X_{lk} n_l\n",
    "\\left(\n",
    "\\operatorname{\\partial}_{\\mathbf X_{ij}}\n",
    "\\langle\\lambda_l\\rangle\n",
    "\\right)\n",
    "\\right]\n",
    "\\mathbf M_{lk}\n",
    "\\\\\n",
    "&\n",
    "=\n",
    "\\textstyle\\sum_{kl}\n",
    "\\left[\n",
    "\\delta_{il} \\delta_{jk} n_l\\langle\\lambda_l\\rangle\n",
    "+\n",
    "\\mathbf X_{lk} n_l\n",
    "\\operatorname{\\partial}_{\\mathbf X_{ij}}\n",
    "\\exp\\left(\\mu_l + \\tfrac 1 2 \\boldsymbol\\Sigma_{ll}\\right)\n",
    "\\right]\n",
    "\\mathbf M_{lk}\n",
    "\\\\\n",
    "&\n",
    "=\n",
    "\\textstyle\\sum_{kl}\n",
    "\\left[\n",
    "\\delta_{il} \\delta_{jk} n_l\\langle\\lambda_l\\rangle\n",
    "+\n",
    "\\tfrac 1 2\n",
    "\\mathbf X_{lk} n_l\\langle\\lambda_l\\rangle\n",
    "\\operatorname{\\partial}_{\\mathbf X_{ij}}\n",
    "\\boldsymbol\\Sigma_{ll}\n",
    "\\right]\n",
    "\\mathbf M_{lk}\n",
    "\\\\\n",
    "&\n",
    "=\n",
    "\\textstyle\\sum_{kl}\n",
    "n_l\\langle\\lambda_l\\rangle\n",
    "\\left[\n",
    "\\delta_{il} \\delta_{jk}\n",
    "+\n",
    "\\tfrac 1 2\n",
    "\\mathbf X_{lk}\n",
    "\\operatorname{\\partial}_{\\mathbf X_{ij}}\n",
    "\\boldsymbol[\\mathbf X\\mathbf X^\\top]_{ll}\n",
    "\\right]\n",
    "\\mathbf M_{lk}\n",
    "\\\\\n",
    "&\n",
    "=\n",
    "\\textstyle\\sum_{kl}\n",
    "n_l\\langle\\lambda_l\\rangle\n",
    "\\left[\n",
    "\\delta_{il} \\delta_{jk}\n",
    "+\n",
    "\\tfrac 1 2\n",
    "\\mathbf X_{lk}\n",
    "\\sum_p \n",
    "\\operatorname{\\partial}_{\\mathbf X_{ij}}\n",
    "\\mathbf X_{lp}^2\n",
    "\\right]\n",
    "\\mathbf M_{lk}\n",
    "\\\\\n",
    "&\n",
    "=\n",
    "\\textstyle\\sum_{kl}\n",
    "n_l\\langle\\lambda_l\\rangle\n",
    "\\left[\n",
    "\\delta_{il} \\delta_{jk}\n",
    "+\n",
    "\\mathbf X_{lk}\n",
    "\\sum_p \n",
    "\\mathbf X_{lp} \\delta_{il} \\delta_{jp}\n",
    "\\right]\n",
    "\\mathbf M_{lk}\n",
    "\\\\\n",
    "&\n",
    "=\n",
    "\\textstyle\\sum_{kl}\n",
    "n_l\\langle\\lambda_l\\rangle\n",
    "\\left[\n",
    "\\delta_{il} \\delta_{jk} \n",
    "+\n",
    "\\mathbf X_{lk} \n",
    "\\mathbf X_{lj} \\delta_{il}\n",
    "\\right]\n",
    "\\mathbf M_{lk}\n",
    "\\\\\n",
    "&\n",
    "=\n",
    "\\textstyle\\sum_{kl}\n",
    "n_l\\langle\\lambda_l\\rangle\n",
    "\\delta_{il}\n",
    "\\left[\n",
    "\\delta_{jk} \n",
    "+\n",
    "\\mathbf X_{lk} \n",
    "\\mathbf X_{lj} \n",
    "\\right]\n",
    "\\mathbf M_{lk}\n",
    "\\\\\n",
    "&\n",
    "=\n",
    "\\textstyle\\sum_{k}\n",
    "n_i\\langle\\lambda_i\\rangle\n",
    "\\left[\n",
    "\\delta_{jk} \n",
    "+\n",
    "\\mathbf X_{ik} \n",
    "\\mathbf X_{ij} \n",
    "\\right]\n",
    "\\mathbf M_{ik}\n",
    "\\\\\n",
    "&\n",
    "=\n",
    "n_i\\langle\\lambda_i\\rangle\n",
    "\\textstyle\\sum_{k}\n",
    "\\left[\n",
    "\\delta_{jk} \n",
    "+\n",
    "\\mathbf X_{ik} \n",
    "\\mathbf X_{ij} \n",
    "\\right]\n",
    "\\mathbf M_{ik}\n",
    "\\\\\n",
    "&\n",
    "=\n",
    "n_i\\langle\\lambda_i\\rangle\n",
    "\\left\\{\n",
    "\\textstyle\\sum_{k}\n",
    "\\left[\n",
    "\\delta_{jk} \n",
    "\\mathbf M_{ik}\n",
    "\\right]\n",
    "+\n",
    "\\textstyle\\sum_{k}\n",
    "\\left[\n",
    "\\mathbf X_{ik} \n",
    "\\mathbf X_{ij} \n",
    "\\mathbf M_{ik}\n",
    "\\right]\n",
    "\\right\\}\n",
    "\\\\\n",
    "&\n",
    "=\n",
    "n_i\\langle\\lambda_i\\rangle\n",
    "\\left[\n",
    "\\mathbf M_{ij}\n",
    "+\n",
    "\\mathbf X_{ij} \n",
    "\\textstyle\\sum_{k}\n",
    "\\mathbf X_{ik} \n",
    "\\mathbf M_{ik}\n",
    "\\right]\n",
    "\\\\\n",
    "&\n",
    "=\n",
    "n_i\\langle\\lambda_i\\rangle\n",
    "\\left[\n",
    "\\mathbf M_{ij}\n",
    "+\n",
    "[ \\mathbf X \\mathbf M^\\top ]_{ii}\n",
    "\\right]\\mathbf X_{ij}\n",
    "\\\\\n",
    "&\n",
    "=\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7c5dca-121b-456d-9d66-3cf370bb403e",
   "metadata": {},
   "source": [
    "\\begin{equation}\\begin{aligned}\n",
    "\\operatorname{\\nabla}_{\\mathbf X} \\left< \\operatorname{\\nabla}_{\\mathbf X} \\mathcal L , \\mathbf M \\right>\n",
    "&=\n",
    "\\operatorname{\\nabla}_{\\mathbf X} \\left< \n",
    "\\left(\n",
    "\\operatorname{diag}\\left[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle\\right] + \\boldsymbol\\Sigma_0^{-1}\\right)\\mathbf X - {\\mathbf X^{+}}^\\top\n",
    ", \\mathbf M \\right>\n",
    "\\\\\n",
    "&=\n",
    "\\operatorname{\\nabla}_{\\mathbf X}\n",
    "\\operatorname{tr}\\left[\n",
    "\\mathbf X^\\top\n",
    "\\operatorname{diag}\\left[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle\\right]\\mathbf M\n",
    "+ \n",
    "\\mathbf X^\\top \\boldsymbol\\Sigma_0^{-1}\\mathbf M\n",
    "- \n",
    "{\\mathbf X^{+}}\\mathbf M\n",
    "\\right]\n",
    "\\\\\n",
    "&=\n",
    "\\operatorname{diag}\\left[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle\\right]\\mathbf M\n",
    "+ \n",
    "\\boldsymbol\\Sigma_0^{-1}\\mathbf M\n",
    "+{\\mathbf X^+}^\\top \\mathbf M^\\top {\\mathbf X^+}^\\top - (\\mathbf I - {\\mathbf X^+}^\\top \\mathbf X^\\top) \\mathbf M \\mathbf X^+ {\\mathbf X^+}^\\top\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281abe8e-e060-4379-afc0-c48fa37691f0",
   "metadata": {},
   "source": [
    "## Inverse-diagonal approximation \n",
    "\n",
    "We consider an approximate posterior covariance of the form\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\boldsymbol\\Sigma^{-1} &\\approx \\boldsymbol\\Sigma_0^{-1} + \\operatorname{diag}\\left[\\frac 1 {\\mathbf v} \\right]\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "This can be optimized using the fixed-point iteration:\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\mathbf v \\gets \\operatorname{diag}\\left[\n",
    "\\left(\\boldsymbol\\Sigma_0^{-1} + \\operatorname{diag}\\left[\\frac 1 {\\mathbf v} \\right]\\right)^{-1}\n",
    "\\right]\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "I can't prove that this converges, but it seems to. It's also difficult to compute. The above matrix inverse is cubic in complexity. Individual marginals can be calculated using Krylov subspace-based algorithms, but I havn't tested it. \n",
    "\n",
    "This can be solved self-consistently by adjusting $\\mathbf v$ until \n",
    "\n",
    "$$\n",
    "\\frac 1 {\\mathbf v} = \\mathbf n \\circ \\langle\\boldsymbol\\lambda\\rangle\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac 1 {\\mathbf v} = \\mathbf n \\circ \\exp\\left(\\boldsymbol\\mu + \\tfrac 1 2 \\operatorname{diag}\\left[\\left(\\boldsymbol\\Sigma_0^{-1} + \\operatorname{diag}\\left[\\tfrac 1 {\\mathbf v}\\right]\\right)^{-1}\\right]\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "My intuition is that there should be some sort of negative-feedback based solution here. Maybe assuming that \n",
    "\n",
    "$$\n",
    "\\mathbf v = \\exp(\\boldsymbol \\mu)\n",
    "$$\n",
    "\n",
    "would work? \n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\mathcal L(\\mathbf v)&=\\mathbf n^\\top \\exp\\left(\\boldsymbol\\mu + \\tfrac 1 2 \\operatorname{diag}[\\boldsymbol\\Sigma]\\right)+ \\tfrac 1 2 \\left \\{ \\operatorname{tr}[\\boldsymbol\\Sigma_0^{-1}\\boldsymbol\\Sigma] - \\ln|\\boldsymbol\\Sigma|\\right\\}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23dfeeb-57ee-49ff-815a-445af8196681",
   "metadata": {},
   "source": [
    "## Let's try this .. chain rule \n",
    "\n",
    "$$\n",
    "\\partial (\\mathbf X ^{-1}) = - \\mathbf X ^{-1} (\\partial \\mathbf X)  \\mathbf X^{-1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf Y = \\mathbf X^{-1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\boldsymbol\\Sigma^{-1} = \n",
    "\\left(\\boldsymbol\\Sigma_0^{-1} + \\operatorname{diag}\\left[\\frac 1 {\\mathbf v} \\right]\\right)^{-1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\partial (\\boldsymbol\\Sigma^{-1}) = - \\boldsymbol\\Sigma^{-1} (\\partial \\operatorname{diag}\\left[\\frac 1 {\\mathbf v} \\right] ) \\boldsymbol\\Sigma^{-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae820f78-6de5-47a8-9229-ac6fa2760b99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
