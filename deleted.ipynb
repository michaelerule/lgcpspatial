{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a08cfda-12d7-4a6c-a845-5936c6878a1e",
   "metadata": {},
   "source": [
    "## Low-rank approximation \n",
    "\n",
    "We consider an approximate posterior covariance of the form\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\boldsymbol\\Sigma^{-1} &\\approx \\mathbf X \\mathbf X^\\top,\\,\\,\\,\\,\\mathbf X\\in\\mathbb R^{L^2\\times K}\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "where $\\mathbf X$ is a tall, thin matrix, with as many rows as there are spatial bins ($L^2$), and $K<L^2$ columns. We view $\\mathbf X$ as being composed of $L^2$ length-$K$ row-vectors $\\mathbf x_k$. \n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\mathbf X^\\top &= \\{ \\mathbf x_1^\\top,...,\\mathbf x_{L^2}^\\top \\}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccb8035-7347-41a8-9bd4-235bc041cdc1",
   "metadata": {},
   "source": [
    "Neglecting terms that do not depend on $\\mathbf X$, the loss to be minimized is:\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\mathcal L(\\mathbf X)&=\\mathbf n^\\top \\exp\\left(\\boldsymbol\\mu + \\tfrac 1 2 \\operatorname{diag}\\left[\\mathbf X \\mathbf X^\\top\\right]\\right)+ \\tfrac 1 2 \\left \\{ \\operatorname{tr}\\left[\\boldsymbol\\Sigma_0^{-1}\\mathbf X \\mathbf X^\\top\\right] - \\ln|\\mathbf X^\\top \\mathbf X |\\right\\}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e420ea7-fb6f-4acb-8753-2aba5f1c7f52",
   "metadata": {},
   "source": [
    "Note that we have used $\\ln|\\mathbf X^\\top \\mathbf X |$ above, rather than $\\ln|\\mathbf X\\mathbf X^\\top|$\n",
    "Since $\\mathbf X \\mathbf X^\\top$ is rank $K<L^2$, it always as a subspace of size $L^2-K$ with zero eigenvalues. This null space doesn't affect the gradient, but it does make the log-determinant undefined. $\\ln|\\mathbf X^\\top \\mathbf X |$ considers only the log-determinant in the low-rank space spanned by $\\mathbf X$, and remains finite. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63b24ab-1765-4b3e-965b-006317593be6",
   "metadata": {},
   "source": [
    "\\begin{equation}\\begin{aligned}\n",
    "%%%% GRADIENT IN v\n",
    "\\operatorname{\\nabla}_{\\mathbf X}\n",
    "\\mathcal L &=\n",
    "\\left(\n",
    "\\operatorname{diag}\\left[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle\\right] + \\boldsymbol\\Sigma_0^{-1}\\right)\\mathbf X - {\\mathbf X^{+}}^\\top\n",
    "\\end{aligned}\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd24f4c-9431-4702-b0de-360404b1ae58",
   "metadata": {},
   "source": [
    "The derivatives of $\\operatorname{tr}\\left[\\boldsymbol\\Sigma_0^{-1}\\mathbf X \\mathbf X^\\top\\right]$ and $\\ln|\\mathbf X \\mathbf X^\\top|$ can be found in The Matrix Cookbook. The gradient of $\\mathbf n^\\top \\exp\\left(\\boldsymbol\\mu+ \\tfrac 1 2 \\operatorname{diag}\\left[\\mathbf X \\mathbf X^\\top\\right]\\right)$ can be solved manually by considering single elements of $\\mathbf X$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1359ed34-73c6-49fa-8962-15aead397ae0",
   "metadata": {},
   "source": [
    "\\begin{equation}\\begin{aligned}\n",
    "\\tfrac{d}{dx_{ij}}\n",
    "\\mathbf n^\\top \\exp\\left(\\boldsymbol\\mu+ \\tfrac 1 2 \\operatorname{diag}\\left[\\mathbf X \\mathbf X^\\top\\right]\\right)\n",
    "&=\n",
    "\\textstyle\\sum_l n_l\\langle\\lambda_l\\rangle\n",
    "\\tfrac12 \\tfrac{d}{dx_{ij}} \\operatorname{diag}\\left[\\mathbf X \\mathbf X^\\top\\right]_l\n",
    "\\\\&=\n",
    "\\textstyle\\sum_l n_l\\langle\\lambda_l\\rangle\n",
    "\\tfrac12\\sum_k \\tfrac{d}{dx_{ij}} \\mathbf x_{lk}^2\n",
    "\\\\&=\n",
    "\\textstyle\\sum_l n_l\\langle\\lambda_l\\rangle\n",
    "\\tfrac12\\sum_k 2 \\mathbf x_{lk} \\delta_{ij=lk}\n",
    "\\\\&=\n",
    "\\textstyle\\sum_l n_l\\langle\\lambda_l\\rangle\n",
    "\\mathbf x_{lj} \\delta_{i=l}\n",
    "\\\\&=\n",
    "n_i\\langle\\lambda_i\\rangle \\mathbf x_{ij}\n",
    "\\\\&=\n",
    "\\left[\\operatorname{diag}[\\mathbf n\\circ \\langle\\boldsymbol\\lambda\\rangle]\\, \\mathbf X\\right]_{ij}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246ff4fa-4007-4077-b4d4-5eed79ab00c9",
   "metadata": {},
   "source": [
    "Writing down the Hessian in $\\mathbf X$ is cumbersome, since it is four-dimensional. However, in practice we only need to calculate the product of the Hessian with a \"vector\", which is in this case a matrix $\\mathbf M$: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1f50a8-7199-45fb-bfcb-1be0f8339b13",
   "metadata": {},
   "source": [
    "\\begin{equation}\\begin{aligned}\n",
    "{}\\left[\\operatorname{H}_{\\mathbf v} \\mathcal L \\right]{\\mathbf M}\n",
    "=\\operatorname{diag}\\left[\\mathbf n \\circ \\langle\\boldsymbol\\lambda\\rangle\\right]\n",
    "\\left[ \\mathbf I\\circ\\mathbf M\\mathbf X^\\top + \\mathbf M \\right]\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b5c053-49a4-438c-a28a-b8cfbec13a6c",
   "metadata": {},
   "source": [
    "Proving this is horrifying. This can be obtained by differentiating the scalar product between the Jacobian and a matrix $\\mathbf M$, $\\operatorname{tr}\\left\\{\\left[\\operatorname{\\nabla}_{\\mathbf X} \\mathcal L\\right]^\\top \\mathbf M\\right\\}$: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2f1fe0-a7f8-484e-be7e-016f5898f5a1",
   "metadata": {},
   "source": [
    "\\begin{equation}\\begin{aligned}\n",
    "\\operatorname{\\nabla}_{\\mathbf X} \\operatorname{tr}\\left\\{\n",
    "\\left[\\operatorname{\\nabla}_{\\mathbf X}\n",
    "\\mathcal L\\right]^\\top \\mathbf M\\right\\} \n",
    "&=\n",
    "\\operatorname{\\nabla}_{\\mathbf X} \\operatorname{tr}\\left\\{\n",
    "\\left[\\left(\\operatorname{diag}\\left[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle\\right] + \\boldsymbol\\Sigma_0^{-1}\\right)\\mathbf X - {\\mathbf X^{+}}^\\top\\right]^\\top \\mathbf M\\right\\}\n",
    "\\\\&=\n",
    "\\operatorname{\\nabla}_{\\mathbf X} \\operatorname{tr}\\left\\{\n",
    "\\left[\\mathbf X^\\top\\left(\\operatorname{diag}\\left[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle\\right] + \\boldsymbol\\Sigma_0^{-1}\\right) - \\mathbf X^{+}\\right] \\mathbf M\\right\\}\n",
    "\\\\&=\n",
    "\\operatorname{\\nabla}_{\\mathbf X} \n",
    "\\operatorname{tr}\\left\\{\n",
    "\\mathbf X^\\top\\left(\\operatorname{diag}\\left[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle\\right] + \\boldsymbol\\Sigma_0^{-1}\\right)\\mathbf M - \\mathbf X^{+}\\mathbf M\\right\\}\n",
    "\\\\\n",
    "&=\n",
    "\\operatorname{\\nabla}_{\\mathbf X}\\operatorname{tr}\\left\\{\n",
    "\\mathbf X^\\top\\operatorname{diag}\\left[\n",
    "\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle\n",
    "\\right]\\mathbf M\n",
    "\\right\\}\n",
    "+\n",
    "\\operatorname{\\nabla}_{\\mathbf X}\\operatorname{tr}\\left\\{\n",
    "\\mathbf X^\\top\\boldsymbol\\Sigma_0^{-1}\\mathbf M\n",
    "\\right\\}\n",
    "- \n",
    "\\operatorname{\\nabla}_{\\mathbf X}\\operatorname{tr}\\left\\{\n",
    "\\mathbf M\\mathbf X^{+}\n",
    "\\right\\}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fa6d2c-5087-481a-8bc6-811ce643ba34",
   "metadata": {},
   "source": [
    "How the hell did you derive this? Is it even correct? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dbfb1a-e771-4d27-a3aa-5deebb3df3ed",
   "metadata": {},
   "source": [
    "It is necessary to derive this element-wise. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b22238-e159-4c8b-a9ba-1733bcb83f5c",
   "metadata": {},
   "source": [
    "\\begin{equation}\\begin{aligned}\n",
    "\\frac{d}{d x_{ij}} \\mathbf n^\\top \\langle\\boldsymbol\\lambda\\rangle\n",
    "&=\n",
    "\\frac{d}{d x_{ij}} \\mathbf n^\\top \\exp\\left(\\boldsymbol\\mu + \\tfrac 1 2 \\operatorname{diag}\\left[\\mathbf X \\mathbf X^\\top\\right]\\right)\n",
    "\\\\&=\n",
    "\\frac{d}{d x_{ij}} \\sum_k n_k \\exp\\left(\\mu_k + \\tfrac 1 2 \\operatorname{diag}\\left[\\mathbf X \\mathbf X^\\top\\right]_k\\right)\n",
    "\\\\&=\n",
    "\\frac{d}{d x_{ij}} \\sum_l n_l \\exp\\left(\\mu_l + \\tfrac 1 2 \\sum_k x_{lk}^2 \\right)\n",
    "\\\\&=\n",
    "\\sum_l n_l \\frac{d}{d x_{ij}}\\exp\\left(\\mu_l + \\tfrac 1 2 \\sum_k x_{lk}^2 \\right)\n",
    "\\\\&=\n",
    "\\sum_l n_l \\langle\\lambda_l\\rangle \\tfrac 1 2 \\sum_k \\frac{d}{d x_{ij}} x_{lk}^2\n",
    "\\\\&=\n",
    "\\sum_l n_l \\langle\\lambda_l\\rangle \\sum_k x_{lk} \\delta_{lk=ij}\n",
    "\\\\&=\n",
    "\\sum_l n_l \\langle\\lambda_l\\rangle x_{lj} \\delta_{l=i}\n",
    "\\\\&=\n",
    "n_i \\langle\\lambda_i\\rangle x_{ij}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260985d1-0a95-4941-9aa5-908fdc05da07",
   "metadata": {},
   "source": [
    "\\begin{equation}\\begin{aligned}\n",
    "\\frac{d}{d x_{kl}}\n",
    "\\frac{d}{d x_{ij}} \\mathbf n^\\top \\langle\\boldsymbol\\lambda\\rangle\n",
    "&=\n",
    "\\frac{d}{d x_{kl}} n_i \\langle\\lambda_i\\rangle x_{ij}\n",
    "\\\\&=\n",
    "n_i \\frac{d}{d x_{kl}} \\langle\\lambda_i\\rangle \n",
    "+n_i \\langle\\lambda_i\\rangle \\frac{d}{d x_{kl}} x_{ij}\n",
    "\\\\&=\n",
    "n_i \\langle\\lambda_i\\rangle \\tfrac 1 2 \\frac{d}{d x_{kl}} \\operatorname{diag}\\left[\\mathbf X \\mathbf X^\\top\\right]_i\n",
    "+n_i \\langle\\lambda_i\\rangle \\delta_{ij=kl}\n",
    "\\\\&=\n",
    "n_i \\langle\\lambda_i\\rangle \\tfrac 1 2 \n",
    "\\sum_m \\frac{d}{d x_{kl}}  \\mathbf x_{im}^2\n",
    "+n_i \\langle\\lambda_i\\rangle \\delta_{ij=kl}\n",
    "\\\\&=\n",
    "n_i \\langle\\lambda_i\\rangle\n",
    "\\sum_m \\mathbf x_{im} \\delta_{im=kl}\n",
    "+n_i \\langle\\lambda_i\\rangle \\delta_{ij=kl}\n",
    "\\\\&=\n",
    "n_i \\langle\\lambda_i\\rangle\n",
    "\\mathbf x_{il} \\delta_{i=k}\n",
    "+n_i \\langle\\lambda_i\\rangle \\delta_{ij=kl}\n",
    "\\\\&=\n",
    "\\delta_{i=k}(\n",
    "n_i \\langle\\lambda_i\\rangle\n",
    "\\mathbf x_{il} \n",
    "+n_i \\langle\\lambda_i\\rangle \\delta_{j=l}\n",
    ")\n",
    "\\end{aligned}\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f2bd6e-ecc3-4d6d-9397-a83f8ba148c4",
   "metadata": {},
   "source": [
    "Scalar product with $\\mathbf M$ ($m_{ij} = (\\mathbf M)_{ij}$). We apply this on the left. \n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\left<\\frac{d}{d x_{kl}}\n",
    "\\frac{d}{d x_{ij}} \\mathbf n^\\top \\langle\\boldsymbol\\lambda\\rangle, \n",
    "\\, \n",
    "\\mathbf M \\right>_{kl}\n",
    "&=\n",
    "\\sum_{ij} m_{ij}\n",
    "\\delta_{i=k}(\n",
    "n_i \\langle\\lambda_i\\rangle\n",
    "\\mathbf x_{il} \n",
    "+n_i \\langle\\lambda_i\\rangle \\delta_{j=l}\n",
    ")\n",
    "\\\\&=\n",
    "\\sum_{j} m_{kj}\n",
    "(\n",
    "n_k \\langle\\lambda_k\\rangle\n",
    "\\mathbf x_{kl} \n",
    "+n_k \\langle\\lambda_k\\rangle \\delta_{j=l}\n",
    ")\n",
    "\\\\&=\n",
    "\\sum_{j} m_{kj}\n",
    "n_k \\langle\\lambda_k\\rangle\n",
    "\\mathbf x_{kl} \n",
    "+\n",
    "\\sum_{j} m_{kj}\n",
    "n_k \\langle\\lambda_k\\rangle \\delta_{j=l}\n",
    "\\\\&=\n",
    "n_k \\langle\\lambda_k\\rangle\n",
    "\\mathbf x_{kl} \\sum_{j} m_{kj}\n",
    "+\n",
    "m_{kl}\n",
    "n_k \\langle\\lambda_k\\rangle\n",
    "\\\\&=\n",
    "n_k \\langle\\lambda_k\\rangle \\left[\n",
    "\\mathbf x_{kl} \\sum_{j} m_{kj}\n",
    "+\n",
    "m_{kl}\n",
    "\\right]\n",
    "\\\\&=\n",
    "\\left\\{\n",
    "\\operatorname{diag}\\left[\\mathbf n \\langle\\boldsymbol\\lambda\\rangle\\right]\n",
    "\\left[\n",
    "\\operatorname{diag}[\\mathbf M \\mathbb 1]\\, \\mathbf X\n",
    "+\n",
    "\\mathbf M\n",
    "\\right]\n",
    "\\right\\}_{kl}\n",
    "\\end{aligned}\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab1cce9-46d7-4988-b244-0ec8b7a1b83b",
   "metadata": {},
   "source": [
    "\\begin{equation}\\begin{aligned}\n",
    "\\tfrac 1 2 \\left \\{ \\operatorname{tr}\\left[\\boldsymbol\\Sigma_0^{-1}\\mathbf X \\mathbf X^\\top\\right] - \\ln|\\mathbf X^\\top \\mathbf X |\\right\\}\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\boldsymbol\\Sigma_0^{-1}\\mathbf X - \\mathbf X^{-\\top}\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\operatorname{tr}[\n",
    "\\mathbf X^\\top \\boldsymbol\\Sigma_0^{-1}\\mathbf M - \\mathbf X^{-1}\\mathbf M\n",
    "]\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\boldsymbol\\Sigma_0^{-1}\\mathbf M + \\mathbf X^{-1}\\mathbf M^\\top \\mathbf X^{-1}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf46660-394d-4c7c-b0da-381d772316cf",
   "metadata": {},
   "source": [
    "We can work with just $\\mathbf X$ as full rank, invertable, but we do need to be able to ake its inverse. This seems to imply that the inverse will diverse if $\\mathbf X$ ever takes on a value that is low-rank. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0ab2a9-1483-4ed3-8eb8-3573f6eb9fb2",
   "metadata": {},
   "source": [
    "\\begin{equation}\\begin{aligned}\n",
    "\\mathcal L(\\mathbf v)&=\\mathbf n^\\top \\exp\\left(\\boldsymbol\\mu + \\tfrac 1 2 \\operatorname{diag}[\\boldsymbol\\Sigma]\\right)+ \\tfrac 1 2 \\left \\{ \\operatorname{tr}[\\boldsymbol\\Sigma_0^{-1}\\boldsymbol\\Sigma] - \\ln|\\boldsymbol\\Sigma|\\right\\}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a1828d-6c15-4942-b929-8761d8b4989a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b524c14-98c8-4ada-b17c-dffcabc6f283",
   "metadata": {},
   "source": [
    "## Reduced Fourier-space approximation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e306adc-4ed0-4266-8833-b1599c2dedc8",
   "metadata": {},
   "source": [
    "\\begin{equation}\\begin{aligned}\n",
    "\\mathcal L(\\mathbf v)&=\\mathbf n^\\top \\exp\\left(\\boldsymbol\\mu + \\tfrac 1 2 \\operatorname{diag}[\\boldsymbol\\Sigma]\\right)+ \\tfrac 1 2 \\left \\{ \\operatorname{tr}[\\boldsymbol\\Sigma_0^{-1}\\boldsymbol\\Sigma] - \\ln|\\boldsymbol\\Sigma|\\right\\}\n",
    "\\end{aligned}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1a2a2b-5f07-4990-92a6-3ce76a89f3a0",
   "metadata": {},
   "source": [
    "We consider an approximate posterior covariance of the form\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\boldsymbol\\Sigma &\\approx \\mathbf F^\\top \\mathbf Q \\mathbf Q^\\top \\mathbf F,\n",
    "\\,\\,\\,\\,\\mathbf Q\\in\\mathbb R^{K\\times K}\n",
    "\\end{aligned}\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e8cac9-64b9-493c-9926-50b759e8dae1",
   "metadata": {},
   "source": [
    "Neglecting terms that do not depend on $\\mathbf Q$, the loss to be minimized is:\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\mathcal L(\\mathbf X)&=\\mathbf n^\\top \\exp\\left(\\boldsymbol\\mu + \\tfrac 1 2 \\operatorname{diag}\\left[\\mathbf F^\\top \\mathbf Q \\mathbf Q^\\top \\mathbf F\\right]\\right)+ \\tfrac 1 2 \\left \\{ \\operatorname{tr}\\left[\\boldsymbol\\Sigma_0^{-1}\\mathbf F^\\top \\mathbf Q \\mathbf Q^\\top \\mathbf F\\right] - \\ln| \\mathbf Q \\mathbf Q^\\top |\\right\\}\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\frac{d}{d\\sigma_{ij}} \\left\\{ \\mathbf n^\\top \\exp\\left(\\boldsymbol\\mu + \\tfrac 1 2 \\operatorname{diag}[\\boldsymbol\\Sigma]\\right)+ \\tfrac 1 2 \\left \\{ \\operatorname{tr}[\\boldsymbol\\Sigma_0^{-1}\\boldsymbol\\Sigma] - \\ln|\\boldsymbol\\Sigma|\\right\\}\n",
    "\\right\\}\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\mathbf n^\\top \\frac{d}{d\\sigma_{ij}} \\exp\\left(\\boldsymbol\\mu + \\tfrac 1 2 \\operatorname{diag}[\\boldsymbol\\Sigma]\\right)\n",
    "+ \n",
    "\\frac 1 2 \\frac{d}{d\\sigma_{ij}} \\operatorname{tr}[\\boldsymbol\\Sigma_0^{-1}\\boldsymbol\\Sigma] \n",
    "- \n",
    "\\frac 1 2 \\frac{d}{d\\sigma_{ij}} \\ln|\\boldsymbol\\Sigma|\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\frac{\\partial\\mathcal L}{\\partial\\Sigma_{ij}}\n",
    "\\tfrac 1 2\\left\\{\\operatorname{diag}[\\mathbf n \\lambda ]+ \\boldsymbol\\Sigma_0^{-1}- \\boldsymbol\\Sigma^{-\\top}\\right\\}_{ij}\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "$$\n",
    "\\frac{\\partial\\mathcal L}{\\partial\\theta_i} = \n",
    "\\operatorname{tr}\\left[\n",
    "\\left(\\frac{\\partial\\mathcal L}{\\partial\\boldsymbol\\Sigma}\n",
    "\\right)^\\top\n",
    "\\frac{\\partial\\boldsymbol\\Sigma}{\\partial \\theta_i}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\mathbf F^\\top  (\\mathbf J^{ij}\\mathbf Q^\\top + \\mathbf Q \\mathbf J^{ji}) \\mathbf F\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "$$\n",
    "\\frac{\\partial\\mathcal L}{\\partial\\theta_i} = \\tfrac 1 2\n",
    "\\operatorname{tr}\\left[\n",
    "\\left(\n",
    "%\n",
    "\\operatorname{diag}[\\mathbf n \\lambda ]+ \\boldsymbol\\Sigma_0^{-1}- \\boldsymbol\\Sigma^{-1}\n",
    "%\n",
    "\\right)\n",
    "\\mathbf F^\\top  (\\mathbf J^{ij}\\mathbf Q^\\top + \\mathbf Q \\mathbf J^{ji}) \\mathbf F\n",
    "\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc84014-6801-44dd-a45c-f50c3f51b60d",
   "metadata": {},
   "source": [
    "$$\n",
    "2QFF^\\top\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a56298c-52eb-44cc-b062-2137501db65b",
   "metadata": {},
   "source": [
    "$A J^{ij}$ puts $i$th column of $A$ in column $j$\n",
    "\n",
    "$J^{ij}A$ puts row $j$ of $A$  in row $i$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fef2a9b-1dfe-4736-bb9b-b027e0519cab",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac\n",
    "{\\partial(\\mathbf F^\\top \\mathbf Q \\mathbf Q^\\top \\mathbf F)_{ij}}\n",
    "{\\partial\\mathbf Q_{kl}}\n",
    "=\n",
    "\\sum_m F_{ki} F_{mj} Q_{ml}\n",
    "+\n",
    "F_{mi} F_{kj} Q_{ml}\n",
    "=\n",
    "F_{ki} (F^\\top Q)_{jl}\n",
    "+\n",
    "F_{kj} (F^\\top Q)_{il}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c919493-0ac9-4dca-97cc-95dc435e287e",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial\\mathcal L}{\\partial\\mathbf Q_{kl}} = \\tfrac 1 2\n",
    "\\operatorname{tr}\\left[\n",
    "\\left(\n",
    "%\n",
    "\\operatorname{diag}[\\mathbf n \\lambda ]+ \\boldsymbol\\Sigma_0^{-1}- \\boldsymbol\\Sigma^{-1}\n",
    "%\n",
    "\\right)\n",
    "\\mathbf F^\\top  (\\mathbf J^{ij}\\mathbf Q^\\top + \\mathbf Q \\mathbf J^{ji}) \\mathbf F\n",
    "\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8374352a-2301-4e9e-b143-a6f59d3f4a73",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sum_m [F_{ki} F_{mj} \n",
    "+\n",
    "F_{mi} F_{kj}] Q_{ml}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7aef9f-93bd-43dd-9d31-e456132bbc36",
   "metadata": {},
   "source": [
    "$$\n",
    "{Q^\\top F A F^\\top]_{qp}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0073ae-a437-4961-9bd7-6d9cc868d0d3",
   "metadata": {},
   "source": [
    "# We need a way to verify derivatives. \n",
    "\n",
    "I'm not sure I feel like .. let's just.. ones. \n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\mathcal L(\\boldsymbol\\mu,\\boldsymbol\\Sigma)\n",
    "&=\n",
    "\\mathbf n^\\top \\left[\\langle\\boldsymbol\\lambda\\rangle-\\bar{\\mathbf y} \\circ \\boldsymbol\\mu\\right]\n",
    "+ \n",
    "\\tfrac 1 2 \\left \\{ \\operatorname{tr}[\\boldsymbol\\Sigma_0^{-1}\\boldsymbol\\Sigma] + \n",
    "{\\boldsymbol\\mu}^\\top{{\\boldsymbol\\Sigma}_0}^{-1}\\boldsymbol\\mu\n",
    "+ \\ln|\\boldsymbol\\Sigma_0| - \\ln|\\boldsymbol\\Sigma|\n",
    "\\right\\}\n",
    "\\\\\n",
    "\\langle\\boldsymbol\\lambda\\rangle &=\n",
    "\\exp\\left(\n",
    "\\boldsymbol\\mu+\\boldsymbol\\mu_0\n",
    "+\n",
    "\\tfrac 1 2 \\operatorname{diag}\\left[\\boldsymbol\\Sigma\\right]\\right)\n",
    "\\end{aligned}\n",
    "\\label{loss}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d92c27-32e3-45eb-8c85-67c470bac2d3",
   "metadata": {},
   "source": [
    "## Variational Bayes: Low-rank approximation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86d05ef-b9e0-43ec-b6bf-0e721ea3e461",
   "metadata": {},
   "source": [
    "We consider an approximate posterior covariance of the form\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\boldsymbol\\Sigma^{-1} &\\approx \\mathbf X \\mathbf X^\\top,\\,\\,\\,\\,\\mathbf X\\in\\mathbb R^{L^2\\times K}\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "where $\\mathbf X$ is a tall, thin matrix, with as many rows as there are spatial bins ($L^2$), and $K<L^2$ columns. We view $\\mathbf X$ as being composed of $L^2$ length-$K$ row-vectors $\\mathbf x_k$. \n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\mathbf X^\\top &= \\{ \\mathbf x_1^\\top,...,\\mathbf x_{L^2}^\\top \\}\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "Neglecting terms that do not depend on $\\mathbf X$, the loss to be minimized is:\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\mathcal L(\\mathbf X)&=\\mathbf n^\\top \\exp\\left(\\boldsymbol\\mu + \\tfrac 1 2 \\operatorname{diag}\\left[\\mathbf X \\mathbf X^\\top\\right]\\right)+ \\tfrac 1 2 \\left \\{ \\operatorname{tr}\\left[\\boldsymbol\\Sigma_0^{-1}\\mathbf X \\mathbf X^\\top\\right] - \\ln|\\mathbf X^\\top \\mathbf X |\\right\\}\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "Note that we have used $\\ln|\\mathbf X^\\top \\mathbf X |$ above, rather than $\\ln|\\mathbf X\\mathbf X^\\top|$\n",
    "Since $\\mathbf X \\mathbf X^\\top$ is rank $K<L^2$, it always as a subspace of size $L^2-K$ with zero eigenvalues. This null space doesn't affect the gradient, but it does make the log-determinant undefined. $\\ln|\\mathbf X^\\top \\mathbf X |$ considers only the log-determinant in the low-rank space spanned by $\\mathbf X$, and remains finite. The Jacobian is:\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "%%%% GRADIENT IN v\n",
    "\\operatorname{\\nabla}_{\\mathbf X}\n",
    "\\mathcal L &=\n",
    "\\left(\n",
    "\\operatorname{diag}\\left[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle\\right] + \\boldsymbol\\Sigma_0^{-1}\\right)\\mathbf X - {\\mathbf X^{+}}^\\top\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "\n",
    "The derivatives of $\\operatorname{tr}\\left[\\boldsymbol\\Sigma_0^{-1}\\mathbf X \\mathbf X^\\top\\right]$ and $\\ln|\\mathbf X \\mathbf X^\\top|$ can be found in The Matrix Cookbook. The gradient of $\\mathbf n^\\top \\exp\\left(\\boldsymbol\\mu+ \\tfrac 1 2 \\operatorname{diag}\\left[\\mathbf X \\mathbf X^\\top\\right]\\right)$ can be solved by considering single elements of $\\mathbf X$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e57369-f30f-42ac-908d-725157f05414",
   "metadata": {},
   "source": [
    "The Hessian-vector product is\n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "\\operatorname{\\nabla}_{\\mathbf X} \\left< \\operatorname{\\nabla}_{\\mathbf X}, \\mathbf M \\right>\n",
    "\\mathcal L \n",
    "&=\n",
    "\\operatorname{\\nabla}_{\\mathbf X} \\left< \n",
    "\\left(\n",
    "\\operatorname{diag}\\left[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle\\right] + \\boldsymbol\\Sigma_0^{-1}\\right)\\mathbf X - {\\mathbf X^{+}}^\\top\n",
    ", \\mathbf M \\right>\n",
    "\\\\\n",
    "&=\n",
    "\\operatorname{\\nabla}_{\\mathbf X}\n",
    "\\operatorname{tr}\\left[\n",
    "\\mathbf X^\\top\n",
    "\\operatorname{diag}\\left[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle\\right]\\mathbf M\n",
    "+ \n",
    "\\mathbf X^\\top \\boldsymbol\\Sigma_0^{-1}\\mathbf M\n",
    "- \n",
    "{\\mathbf X^{+}}\\mathbf M\n",
    "\\right]\n",
    "\\\\\n",
    "&=\n",
    "\\operatorname{diag}\\left[\\mathbf n\\circ\\langle\\boldsymbol\\lambda\\rangle\\right]\\mathbf M\n",
    "+ \n",
    "\\boldsymbol\\Sigma_0^{-1}\\mathbf M\n",
    "+{\\mathbf X^+}^\\top \\mathbf M^\\top {\\mathbf X^+}^\\top - (\\mathbf I - {\\mathbf X^+}^\\top \\mathbf X^\\top) \\mathbf M \\mathbf X^+ {\\mathbf X^+}^\\top\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "The derivative involving the pseudoinverse is given in Goulob and Pereya (1972) Eq. 4.12."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
