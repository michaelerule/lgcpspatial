{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52865b21-c031-49b6-8bee-1561d33dbc5b",
   "metadata": {},
   "source": [
    "# Gradient checks 2\n",
    "\n",
    "Extend `gradient checks 1` to bring it closer to the convolutional LGCP use-case. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6abd94f-88f0-43b2-ab3f-7ccf6af4ef55",
   "metadata": {},
   "source": [
    "## Load Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "2ffcae18-c6d6-4766-a04a-78db7953abb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shadow all pylab functions and numpy with the Jax versions\n",
    "# Keep numpy around as np0 for easier RNG, array assignments\n",
    "import jax\n",
    "import jax.numpy as np\n",
    "import numpy.random as npr\n",
    "from jax               import jit, grad, vmap\n",
    "from jax.config        import config\n",
    "from jax.scipy.special import logsumexp\n",
    "from jax.numpy         import *\n",
    "from jax import jacfwd, jacrev\n",
    "from jax import lax\n",
    "from jax.numpy.fft import *\n",
    "from jax.numpy.linalg import *\n",
    "\n",
    "logdet = lambda A:jax.numpy.linalg.slogdet(A)[1]\n",
    "\n",
    "def hess(f,inparam):\n",
    "    return jacfwd(jacrev(f,inparam),inparam)\n",
    "\n",
    "def hvp(f, x, v):\n",
    "    return grad(lambda x: vdot(grad(f)(x), v))(x)\n",
    "\n",
    "def slog(x,minrate = 1e-10):\n",
    "    return log(maximum(minrate,x))\n",
    "\n",
    "def sexp(x,bound = 10):\n",
    "    return exp(clip(x,-bound,bound))\n",
    "\n",
    "from numpy.linalg import cholesky as chol\n",
    "\n",
    "def vec(X):\n",
    "    return X.ravel()\n",
    "\n",
    "# Convolve with vector\n",
    "def conv(K,v):\n",
    "    v = v.reshape(L,L)\n",
    "    return real(ifft2(fft2(v)*K)).ravel()\n",
    "\n",
    "# Convolve with matrix\n",
    "def conm(K,M):\n",
    "    N  = M.shape[-1]\n",
    "    M  = M.reshape(L,L,N)\n",
    "    Mf = fft2(M,axes=(0,1))\n",
    "    Cf = K[:,:,None]*Mf\n",
    "    C  = real(ifft2(Cf,axes=(0,1)))\n",
    "    return C.reshape(T,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44401b68-fb29-4de0-87cb-87c5f89948b0",
   "metadata": {},
   "source": [
    "## Direct parameterization of Σ\n",
    "\n",
    "- The domain is now 2D\n",
    "- The prior is now a convolution\n",
    "\n",
    "No real point in optimizing this one, since parameterization in Σ is never practical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "e1cfb034-cac8-44e0-9dd3-38f5f71b06de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.07887090559234e-14\n",
      "8.01598787347757e-15\n",
      "6.778932970519236e-15\n",
      "5.1656456889759287e-14\n",
      "4.629323169247357e-12\n"
     ]
    }
   ],
   "source": [
    "L  = 10\n",
    "T  = L*L\n",
    "μ  = randn(L,L)\n",
    "μ0 = randn(L,L)-3\n",
    "\n",
    "# Prior is now a convolution\n",
    "# Make kernel\n",
    "w  = arange(L)-L/2\n",
    "K0 = fftshift(exp(-abs(w[:,None]+1j*w[None,:])**2/2))\n",
    "Kf = maximum(1e-6,real(fft2(K0,norm='ortho')))\n",
    "Λf = 1/Kf\n",
    "K0 = real(ifft2(Kf))\n",
    "Λ0 = real(ifft2(Λf))\n",
    "\n",
    "# simulated visit and spike counts\n",
    "n  = np0.random.poisson(0.2,(L,L))\n",
    "λ0 = sexp(μ0)\n",
    "y  = np0.random.poisson(λ0)\n",
    "\n",
    "# guess for posterior covariance\n",
    "X  = randn(T,T)*0.1\n",
    "Σ  = X@X.T + eye(T)*1e-2\n",
    "\n",
    "# Flatten 2D\n",
    "μ0 = μ0.ravel()\n",
    "μ  = μ.ravel()\n",
    "n  = n.ravel()\n",
    "y  = y.ravel()\n",
    "\n",
    "# random vectors for checking gradients\n",
    "u  = randn(T)\n",
    "M  = randn(T,T)\n",
    "\n",
    "# Inefficient but for the hessian we need the full prior\n",
    "Λ0matrix = conm(Λf,eye(T))\n",
    "\n",
    "def loss(μ,Σ):\n",
    "    λ     = exp(μ+μ0+diag(Σ)/2)\n",
    "    ε     = λ - y*μ\n",
    "    trΛ0Σ = trace(conm(Λf,Σ)) # TODO fix this one\n",
    "    μΛ0μ  = μ.T @ conv(Λf,μ)\n",
    "    lndΣ  = logdet(Σ)\n",
    "    lndΣ0 = sum(log(Kf))\n",
    "    return n@ε + (trΛ0Σ + μΛ0μ - lndΣ + lndΣ0)/2\n",
    "\n",
    "# Gradient in μ\n",
    "def Jμ1(μ,Σ):\n",
    "    λ = sexp(μ+μ0+diag(Σ)/2)\n",
    "    return n*(λ-y) + conv(Λf,μ)\n",
    "print(mean(abs(Jμ1(μ,Σ) -grad(loss,0)(μ,Σ))))\n",
    "\n",
    "# Gradient in Σ\n",
    "def JΣ1(μ,Σ):\n",
    "    nλ = n*sexp(μ+μ0+diag(Σ)/2)\n",
    "    D  = diag(nλ)\n",
    "    Λ  = inv(Σ)\n",
    "    return (D + Λ0matrix - Λ)/2\n",
    "print(mean(abs(JΣ1(μ,Σ)-grad(loss,1)(μ,Σ))))\n",
    "\n",
    "# Hessian in μ\n",
    "def Hμ1(μ,Σ):\n",
    "    nλ = n*sexp(μ+μ0+diag(Σ)/2)\n",
    "    D  = diag(nλ)\n",
    "    return D + Λ0matrix\n",
    "print(mean(abs(Hμ1(μ,Σ)-hess(loss,0)(μ,Σ))))\n",
    "\n",
    "# Hessian-vector product for μ\n",
    "def Hvμ1(μ,Σ,u):\n",
    "    nλ = n*sexp(μ+μ0+diag(Σ)/2)\n",
    "    D  = diag(nλ)\n",
    "    return D@u + conv(Λf,u)\n",
    "Hvμ = lambda u: grad(lambda μ: vdot(grad(loss,0)(μ,Σ), u))(μ)\n",
    "print(mean(abs(Hvμ1(μ,Σ,u)-Hvμ(u))))\n",
    "\n",
    "# Hessian-vector product for Σ\n",
    "def HvΣ1(μ,Σ,M):\n",
    "    nλ = n*sexp(μ+μ0+diag(Σ)/2)\n",
    "    Λ  = pinv(Σ)\n",
    "    return diag(nλ*diag(M))/4 + Λ@M.T@Λ/2\n",
    "HvΣ = lambda M: grad(lambda Σ: vdot(grad(loss,1)(μ,Σ),M))(Σ)\n",
    "print(mean(abs(HvΣ1(μ,Σ,M)-HvΣ(M))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a31d05a-af26-473d-8251-d95008227977",
   "metadata": {},
   "source": [
    "## Parameterize at Σ = A diag[v] A'\n",
    "\n",
    "- A is now a convolution\n",
    "\n",
    "This one is worth optimizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "cd3ca5d4-d834-434e-aeab-483b32c28e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.07887090559234e-14\n",
      "4.263256414560601e-16\n",
      "5.755396159656811e-14\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "A  = randn(L,L)*0.1\n",
    "Af = real(fft2(A))\n",
    "G  = A*A\n",
    "Gf = real(fft2(G))\n",
    "v  = exp(randn(T)-2)\n",
    "\n",
    "# This term enters into the variance optimization\n",
    "diagΛ0  = mean(Λf)*ones(L*L)\n",
    "diagAΛA = mean(Λf*Gf)*ones(L*L)\n",
    "\n",
    "def loss2(μ,v):\n",
    "    ν = conv(Gf,v)\n",
    "    λ = exp(μ+μ0+ν/2)\n",
    "    ε = λ - y*μ\n",
    "    trΛ0Σ = diagAΛA@v\n",
    "    μΛ0μ  = μ.T @ conv(Λf,μ)\n",
    "    lndΣ  = sum(slog(v))\n",
    "    lndΣ0 = sum(log(Kf))\n",
    "    return n@ε + trΛ0Σ/2 + μΛ0μ/2 + lndΣ0/2 - lndΣ/2\n",
    "\n",
    "# Gradient in μ\n",
    "def Jμ2(μ,v):\n",
    "    ν = conv(Gf,v)\n",
    "    λ = sexp(μ+μ0+ν/2)\n",
    "    return n*(λ-y) + conv(Λf,μ)\n",
    "print(mean(abs(Jμ2(μ,v) -grad(loss2,0)(μ,v))))\n",
    "\n",
    "# Gradient in v\n",
    "def Jv2(μ,v):\n",
    "    ν  = conv(Gf,v)\n",
    "    nλ = n*sexp(μ+μ0+ν/2)\n",
    "    return conv(Gf,nλ)/2 + diagAΛA/2 - 1/v/2\n",
    "print(mean(abs(grad(loss2,1)(μ,v)-Jv2(μ,v) )))\n",
    "\n",
    "# Hessian-vector product for μ\n",
    "def Hvμ2(μ,v,u):\n",
    "    ν  = conv(Gf,v)\n",
    "    nλ = n*sexp(μ+μ0+ν/2)\n",
    "    return nλ*u + conv(Λf,u)\n",
    "Hvμ = lambda u: grad(lambda μ: vdot(grad(loss2,0)(μ,v), u))(μ)\n",
    "print(mean(abs(Hvμ2(μ,v,u)-Hvμ(u))))\n",
    "\n",
    "# Hessian-vector product for v\n",
    "def Hvv2(μ,v,u):\n",
    "    ν  = conv(Gf,v)\n",
    "    nλ = n*sexp(μ+μ0+ν/2)\n",
    "    return 0.25*conv(Gf,nλ*conv(Gf,u)) + 0.5*v**-2*u\n",
    "\n",
    "HvΣ = lambda u: grad(lambda v:vdot(grad(loss2,1)(μ,v),u))(v)\n",
    "print(mean(abs(Hvv2(μ,v,u)-HvΣ(u))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d884647-2231-405a-b537-b5919e693c63",
   "metadata": {},
   "source": [
    "## Parameterize as Σ = XX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "e5ed072b-458a-4a6f-83a3-3182837fa872",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opt_einsum import contract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "c067fbc5-f25f-4bf3-98a5-7a4f342f549f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.07887090559234e-14\n",
      "5.4143356464919635e-14\n",
      "7.889300324137594e-14\n",
      "8.995137967815481e-14\n"
     ]
    }
   ],
   "source": [
    "R = 4\n",
    "X = randn(T,R)\n",
    "M = randn(T,R)\n",
    "\n",
    "lndΣ0 = sum(log(Kf))\n",
    "\n",
    "def loss3(μ,X):\n",
    "    λ = exp(μ+μ0+sum(X**2,1)/2)\n",
    "    ε = λ-y*μ\n",
    "    trΛ0Σ = sum(X*conm(Λf,X))\n",
    "    μΛ0μ  = μ.T @ conv(Λf,μ)\n",
    "    lndΣ  = logdet(X.T@X)\n",
    "    return n@ε + μΛ0μ/2 + trΛ0Σ/2 + lndΣ0/2 - lndΣ/2\n",
    "\n",
    "# Gradient in μ\n",
    "def Jμ3(μ,X):\n",
    "    λ = exp(μ+μ0+sum(X**2,1)/2)\n",
    "    return n*(λ-y) + conv(Λf,μ) \n",
    "print(mean(abs(Jμ3(μ,X) -grad(loss3,0)(μ,X))))\n",
    "\n",
    "# Hessian-vector-product for μ\n",
    "def Hvμ3(μ,X,u):\n",
    "    nλ = n*exp(μ+μ0+sum(X**2,1)/2)\n",
    "    return nλ*u + conv(Λf,u)\n",
    "Hvμ = lambda u: grad(lambda μ: vdot(grad(loss3,0)(μ,X), u))(μ)\n",
    "print(mean(abs(Hvμ3(μ,X,u)-Hvμ(u))))\n",
    "\n",
    "# Gradient in X\n",
    "def JX3(μ,X):\n",
    "    nλ = n*exp(μ+μ0+sum(X**2,1)/2)\n",
    "    P  = pinv(X)\n",
    "    return nλ[:,None]*X + conm(Λf,X)  - P.T\n",
    "print(mean(abs(JX3(μ,X)-grad(loss3,1)(μ,X))))\n",
    "\n",
    "# Hessian-vector-product for X\n",
    "def HvX3(μ,X,M):\n",
    "    nλ   = n*exp(μ+μ0+sum(X**2,1)/2)\n",
    "    xm   = sum(X*M,1)\n",
    "    P    = pinv(X)\n",
    "    Pt   = P.T\n",
    "    PPt  = P@Pt\n",
    "    #dpnv = Pt@(M.T@Pt+(X.T@M)@PPt) - M@PPt\n",
    "    dpnv = contract('ji,kj,lk->il',P,M,P)+\\\n",
    "        contract('ji,kj,km,mn,ln->il',P,X,M,P,P)-\\\n",
    "        contract('ij,jk,lk->il',M,P,P)\n",
    "    return nλ[:,None]*(M + xm[:,None]*X) + conm(Λf,M) + dpnv\n",
    "\n",
    "HvX = lambda M: grad(lambda X: vdot(grad(loss3,1)(μ,X),M))(X)\n",
    "print(mean(abs(HvX3(μ,X,M)-HvX(M))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cab064-1c3e-495c-aefd-623ec3423d56",
   "metadata": {},
   "source": [
    "## Parameterize as Σ = XX', quadratic instead of exponential observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "578728db-eacc-45e3-b7c0-f27bb13fa520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.07887090559234e-14\n",
      "5.4996007747831756e-14\n",
      "5.717204487609707e-14\n",
      "1.1760370455249358e-13\n"
     ]
    }
   ],
   "source": [
    "R = 4\n",
    "X = randn(T,R)\n",
    "M = randn(T,R)\n",
    "\n",
    "lndΣ0 = sum(log(Kf))\n",
    "\n",
    "def loss3(μ,X):\n",
    "    λ = exp(μ+μ0)*(1+sum(X**2,1)/2)\n",
    "    ε = λ-y*μ\n",
    "    trΛ0Σ = sum(X*conm(Λf,X))\n",
    "    μΛ0μ  = μ.T @ conv(Λf,μ)\n",
    "    lndΣ  = logdet(X.T@X)\n",
    "    return n@ε + μΛ0μ/2 + trΛ0Σ/2 + lndΣ0/2 - lndΣ/2\n",
    "\n",
    "# Gradient in μ\n",
    "def Jμ3(μ,X):\n",
    "    λ = exp(μ+μ0)*(1+sum(X**2,1)/2)\n",
    "    return n*(λ-y) + conv(Λf,μ) \n",
    "print(mean(abs(Jμ3(μ,X) -grad(loss3,0)(μ,X))))\n",
    "\n",
    "# Hessian-vector-product for μ\n",
    "def Hvμ3(μ,X,u):\n",
    "    nλ = n*exp(μ+μ0)*(1+sum(X**2,1)/2)\n",
    "    return nλ*u + conv(Λf,u)\n",
    "Hvμ = lambda u: grad(lambda μ: vdot(grad(loss3,0)(μ,X), u))(μ)\n",
    "print(mean(abs(Hvμ3(μ,X,u)-Hvμ(u))))\n",
    "\n",
    "# Gradient in X\n",
    "def JX3(μ,X):\n",
    "    nλ = n*exp(μ+μ0)\n",
    "    P  = pinv(X)\n",
    "    return nλ[:,None]*X + conm(Λf,X)  - P.T\n",
    "print(mean(abs(JX3(μ,X)-grad(loss3,1)(μ,X))))\n",
    "\n",
    "# Hessian-vector-product for X\n",
    "def HvX3(μ,X,M):\n",
    "    nλ   = n*exp(μ+μ0)\n",
    "    P    = pinv(X)\n",
    "    Pt   = P.T\n",
    "    PPt  = P@Pt\n",
    "    #dpnv = Pt@(M.T@Pt+(X.T@M)@PPt) - M@PPt\n",
    "    dpnv = einsum('ji,kj,lk->il',P,M,P)+\\\n",
    "        einsum('ji,kj,km,mn,ln->il',P,X,M,P,P)-\\\n",
    "        einsum('ij,jk,lk->il',M,P,P)\n",
    "    return nλ[:,None]*M + conm(Λf,M) + dpnv\n",
    "\n",
    "HvX = lambda M: grad(lambda X: vdot(grad(loss3,1)(μ,X),M))(X)\n",
    "print(mean(abs(HvX3(μ,X,M)-HvX(M))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58048767-5d44-4125-a052-ed613d6ee62d",
   "metadata": {},
   "source": [
    "## Parameterize as Σ = F'QQ'F where F is a clipped orthonormal basis and Q is a small square matrix\n",
    "\n",
    "- Will come back to this at the end, replacing F with a discrete cosine transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "3e303441-2b0e-46a6-9f33-f4e9d3c7e44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.361885082189481e-17\n",
      "μ jac 8.07887090559234e-14\n",
      "μ hvp 5.158540261618327e-14\n",
      "Q jac 4.307481613663455e-09\n",
      "Q hvp 1.013903475170741e-06\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import special_ortho_group\n",
    "\n",
    "F = special_ortho_group.rvs(T)\n",
    "R = T#//2\n",
    "F = F[:R]\n",
    "print(mean(abs(F@conj(F.T))-eye(R)))\n",
    "\n",
    "Q = (randn(R,R) + eye(R))*1e-4\n",
    "M = (randn(R,R) + eye(R))*1e-4\n",
    "\n",
    "# Used for grad Q\n",
    "Λ0Ft = conm(Λf,F.T)\n",
    "\n",
    "def loss4(μ,Q):\n",
    "    FQ = F.T@Q\n",
    "    Σ  = FQ@FQ.T\n",
    "    λ  = exp(μ+μ0+diag(Σ)/2)\n",
    "    ε  = λ-y*μ\n",
    "    trΛ0Σ = sum(FQ*conm(Λf,FQ))\n",
    "    μΛ0μ  = μ.T @ conv(Λf,μ)\n",
    "    lndΣ0 = sum(log(Kf))\n",
    "    lndΣ  = logdet(Q@Q.T)\n",
    "    return n@ε + trΛ0Σ/2 + μΛ0μ/2 + lndΣ0/2 - lndΣ/2\n",
    "\n",
    "# Gradient in μ\n",
    "def Jμ4(μ,Q):\n",
    "    FQ = F.T@Q\n",
    "    Σ  = FQ@FQ.T\n",
    "    λ  = exp(μ+μ0+diag(Σ)/2)\n",
    "    return n*(λ-y) + conv(Λf,μ)\n",
    "print('μ jac',mean(abs(Jμ4(μ,Q)-grad(loss4,0)(μ,Q))))\n",
    "\n",
    "def Hvμ4(μ,Q,u):\n",
    "    FQ = F.T@Q\n",
    "    Σ  = FQ@FQ.T\n",
    "    nλ = n*exp(μ+μ0+diag(Σ)/2)\n",
    "    return nλ*u + conv(Λf,u)\n",
    "Hvμ = lambda u: grad(lambda μ: vdot(grad(loss4,0)(μ,Q), u))(μ)\n",
    "print('μ hvp',mean(abs(Hvμ4(μ,Q,u)-Hvμ(u))))\n",
    "\n",
    "# Gradient in Q\n",
    "def JQ4(μ,Q):\n",
    "    FQ = F.T@Q\n",
    "    Σ  = FQ@FQ.T\n",
    "    nλ = n*exp(μ+μ0+diag(Σ)/2)\n",
    "    P  = pinv(Q)\n",
    "    return F  @ (Λ0Ft + nλ[:,None] * F.T) @ Q - P.T\n",
    "print('Q jac',mean(abs(JQ4(μ,Q) -grad(loss4,1)(μ,Q))))\n",
    "\n",
    "def HvQ4(μ,Q,M):\n",
    "    P    = pinv(Q)\n",
    "    Pt   = P.T\n",
    "    PPt  = P@Pt\n",
    "    FQ = F.T@Q\n",
    "    Σ  = FQ@FQ.T\n",
    "    nλ = n*exp(μ+μ0+diag(Σ)/2)\n",
    "    D  = diag(nλ)\n",
    "    r  = nλ * diag(F.T@(M@Q.T)@F)\n",
    "    c  = ((F*nλ)@F.T)@M + ((F*r)@F.T)@Q\n",
    "    return c + (F@Λ0Ft)@M + Pt@M.T@Pt\n",
    "HvQ = lambda M: grad(lambda Q:vdot(grad(loss4,1)(μ,Q),M))(Q)\n",
    "print('Q hvp',mean(abs(HvQ4(μ,Q,M)-HvQ(M))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0d4308-1d8b-46d8-a7c0-e17fda6613e5",
   "metadata": {},
   "source": [
    "## Parameterize as Σ = inv( Λ + diag[p] )\n",
    "\n",
    "Skipping this one since I have no idea how to quickly get the marginal variances. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54812940-c401-44a6-b27a-4e86301c4a4e",
   "metadata": {},
   "source": [
    "# Hartley transform\n",
    "\n",
    "Replace F with the unitary Fourier transform. Double the domain size so that things remain real. Previously we had some difficulty with this. We will try to avoid that by working the whole problem on size (2L)²."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "4de78a44-1c5f-449d-b1de-16811d86f1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check unitary 6.661338147750939e-16\n",
      "Check involution 6.661338147750939e-16\n",
      "μ jac 8.07887090559234e-14\n",
      "μ hvp 5.755396159656811e-14\n",
      "Q jac 1.5730532407817744e-09\n",
      "Q hvp 3.660276452085221e-07\n"
     ]
    }
   ],
   "source": [
    "F = array([fft2(x.reshape(L,L),norm='ortho').ravel() for x in eye(T)]).T\n",
    "F = real(F) + imag(F)\n",
    "print('Check unitary',max(abs(F@F.T-eye(T))))\n",
    "print('Check involution',max(abs(F@F-eye(T))))\n",
    "\n",
    "R = T\n",
    "F = F[:R,:]\n",
    "Q = (randn(R,R) + eye(R))*1e-4\n",
    "M = (randn(R,R) + eye(R))*1e-4\n",
    "\n",
    "# Used for grad Q\n",
    "Λ0Ft = conm(Λf,F.T)\n",
    "\n",
    "def loss4(μ,Q):\n",
    "    FQ = F.T@Q\n",
    "    Σ  = FQ@FQ.T\n",
    "    λ  = exp(μ+μ0+diag(Σ)/2)\n",
    "    ε  = λ-y*μ\n",
    "    trΛ0Σ = sum(FQ*conm(Λf,FQ))\n",
    "    μΛ0μ  = μ.T @ conv(Λf,μ)\n",
    "    lndΣ0 = sum(log(Kf))\n",
    "    lndΣ  = logdet(Q@Q.T)\n",
    "    return n@ε + trΛ0Σ/2 + μΛ0μ/2 + lndΣ0/2 - lndΣ/2\n",
    "\n",
    "def Jμ4(μ,Q):\n",
    "    FQ = F.T@Q\n",
    "    Σ  = FQ@FQ.T\n",
    "    λ  = exp(μ+μ0+diag(Σ)/2)\n",
    "    return n*(λ-y) + conv(Λf,μ)\n",
    "print('μ jac',mean(abs(Jμ4(μ,Q)-grad(loss4,0)(μ,Q))))\n",
    "\n",
    "def Hvμ4(μ,Q,u):\n",
    "    FQ = F.T@Q\n",
    "    Σ  = FQ@FQ.T\n",
    "    nλ = n*exp(μ+μ0+diag(Σ)/2)\n",
    "    return nλ*u + conv(Λf,u)\n",
    "Hvμ = lambda u: grad(lambda μ: vdot(grad(loss4,0)(μ,Q), u))(μ)\n",
    "print('μ hvp',mean(abs(Hvμ4(μ,Q,u)-Hvμ(u))))\n",
    "\n",
    "def JQ4(μ,Q):\n",
    "    FQ = F.T@Q\n",
    "    Σ  = FQ@FQ.T\n",
    "    nλ = n*exp(μ+μ0+diag(Σ)/2)\n",
    "    P  = inv(Q)\n",
    "    return F  @ (Λ0Ft + nλ[:,None] * F.T) @ Q - P.T\n",
    "print('Q jac',mean(abs(JQ4(μ,Q) -grad(loss4,1)(μ,Q))))\n",
    "\n",
    "def HvQ4(μ,Q,M):\n",
    "    P   = inv(Q)\n",
    "    Pt  = P.T\n",
    "    PPt = P@Pt\n",
    "    FQ = F.T@Q\n",
    "    Σ  = FQ@FQ.T\n",
    "    nλ = n*exp(μ+μ0+diag(Σ)/2)\n",
    "    D  = diag(nλ)\n",
    "    r  = nλ * diag(F.T@(M@Q.T)@F)\n",
    "    c  = ((F*nλ)@F.T)@M + ((F*r)@F.T)@Q\n",
    "    return c + (F@Λ0Ft)@M + Pt@M.T@Pt\n",
    "HvQ = lambda M: grad(lambda Q:vdot(grad(loss4,1)(μ,Q),M))(Q)\n",
    "print('Q hvp',mean(abs(HvQ4(μ,Q,M)-HvQ(M))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f36389-080a-4629-abb4-fde5f63bcbb6",
   "metadata": {},
   "source": [
    "## Fast Hartley transform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "2a571a76-8795-4b5b-8044-bfdc001909fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fht2(x):\n",
    "    f = fft2(x.reshape(L,L),norm='ortho')\n",
    "    return real(f)+imag(f)\n",
    "\n",
    "def fht(*args):\n",
    "    f = fft(*args,norm='ortho')\n",
    "    return real(f)+imag(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "id": "ec72a95a-1461-47bf-8664-50925e21e058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check FHT is involution 3.1579208913678184e-18\n",
      "Keeping R=11 out of 100 components\n",
      "Check approximation accuracy 0.05044533473812045\n",
      "check F orthonormal 6.661338147750939e-16\n",
      "check expand/collapse matrix 5.551115123125783e-17\n",
      "check expand/collapse vectors 1.3877787807814457e-17\n",
      "check collapse matrix 2.6645352591003757e-15\n",
      "check FQ 2.0816681711721685e-17\n",
      "check FQF' 5.204170427930421e-18\n",
      "check lower triangular inverse 2.0463630789890885e-12\n"
     ]
    }
   ],
   "source": [
    "Kh = fht2(K0)\n",
    "K1 = fht2(Kh)\n",
    "print('check FHT is involution',mean(abs(K1-K0)))\n",
    "\n",
    "#  Pick which components to keep \n",
    "thr    = percentile(abs(Kh),90)\n",
    "keep2d = abs(Kh)>thr\n",
    "keep   = where(keep2d.ravel())[0]\n",
    "R      = len(keep)\n",
    "print('Keeping R=%d out of %d components'%(R,T))\n",
    "print('Check approximation accuracy',max(abs(fht2(Kh*keep2d)-K0)))\n",
    "\n",
    "# Jax can't do assignment so we build these projection matrices\n",
    "down = eye(T)[keep]\n",
    "up   = down.T\n",
    "\n",
    "# TODO later\n",
    "# Slightly faster to separate\n",
    "keep1d = any(keep2d,1)\n",
    "keeprc = where(keep2d[keep1d,:][:,keep1d].ravel())[0]\n",
    "\n",
    "def collapse(v):\n",
    "    v = v.reshape(L,L)\n",
    "    v = fht2(v)\n",
    "    v = v.ravel()[keep]\n",
    "    return v\n",
    "\n",
    "def expand(x):\n",
    "    v = (up@x).reshape(L,L)\n",
    "    v = fht2(v)\n",
    "    return v.ravel()\n",
    "\n",
    "def collapseAleft(A):\n",
    "    ''' Collapse L²×L² matrix to subspace on left (todo: optimize me)'''\n",
    "    A = A.reshape(L*L,L,L)\n",
    "    A = array([collapse(a) for a in A]).T\n",
    "    return A\n",
    "\n",
    "def collapseAleft(A):\n",
    "    ''' Collapse L²×L² matrix to subspace on left (todo: optimize me)'''\n",
    "    print(A.shape)\n",
    "    n = A.shape[0]\n",
    "    A = A.reshape(n,L,L)\n",
    "    A = array([collapse(a) for a in A]).T\n",
    "    return A\n",
    "\n",
    "def collapseAright(A):\n",
    "    ''' Collapse L²×L² matrix to subspace on left (todo: optimize me)'''\n",
    "    print(A.shape)\n",
    "    n = A.shape[1]\n",
    "    A = A.reshape(L,L,n).T\n",
    "    A = array([collapse(a) for a in A]).T\n",
    "    return A\n",
    "\n",
    "def collapseA(A):\n",
    "    ''' Collapse L²×L² matrix to subspace (todo: optimize me)'''\n",
    "    A = A.reshape(L*L,L,L)\n",
    "    A = array([collapse(a) for a in A]).T\n",
    "    A = A.reshape(R,L,L)\n",
    "    A = array([collapse(a) for a in A]).T\n",
    "    return A\n",
    "\n",
    "def expandAleft(A):\n",
    "    '''Expand compressed representation on the left'''\n",
    "    return array([expand(a) for a in A.T]).T\n",
    "\n",
    "def expandAright(A):\n",
    "    '''Expand compressed representation on the right'''\n",
    "    return array([expand(a) for a in A])\n",
    "\n",
    "def expandA(A):\n",
    "    return expandAleft(expandAright(A))\n",
    "\n",
    "# Sanity check : construct as matrix and verify fast routines match \n",
    "F = array([fft2(x.reshape(L,L),norm='ortho').ravel() for x in eye(T)]).T\n",
    "F = real(F) + imag(F)\n",
    "F = F[keep,:]\n",
    "print('check F orthonormal',max(abs(F@F.T-eye(R))))\n",
    "P = F.T@F\n",
    "\n",
    "H = circulant(K0.ravel())\n",
    "print('check expand/collapse matrix',max(abs(expandA(collapseA(H))-P@H@P)))\n",
    "print('check expand/collapse vectors',max(abs(expand(collapse(K0))-P@K0.ravel())))\n",
    "\n",
    "A = randn(T,T)\n",
    "print('check collapse matrix',max(abs(F@A@F.T - collapseA(A))))\n",
    "\n",
    "Λf    = 1/Kf\n",
    "Λ0Ft   = conm(Λf,F.T)\n",
    "lndΣ0 = sum(log(Kf))\n",
    "\n",
    "Q = tril(randn(R,R) + eye(R))*1e-1\n",
    "M = tril(randn(R,R) + eye(R))*1e-1\n",
    "\n",
    "print('check FQ',max(abs(F.T@Q-expandAleft(Q))))\n",
    "print('check FQF\\'',max(abs(F.T@Q@Q.T@F-expandA(Q@Q.T))))\n",
    "\n",
    "from scipy.linalg.lapack import dtrtri\n",
    "def ltinv(ch):\n",
    "    q,info = scipy.linalg.lapack.dtrtri(ch,lower=True)\n",
    "    if info!=0:\n",
    "        raise ValueError(\n",
    "            'lapack.dtrtri encountered illegal argument in position %d'%-info\n",
    "            if info<0 else\n",
    "            'lapack.dtrtri encountered zero diagonal element at %d'%info)\n",
    "    return q\n",
    "\n",
    "print('check lower triangular inverse',max(abs(inv(Q) - ltinv(Q))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "id": "2d2ee8cc-ab93-4c64-a30b-e56fd449a9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss FHT check 0.0011935656220884994\n",
      "μ jac 2.626321395197806e-05\n",
      "μ hvp 5.6274984672199934e-14\n",
      "Q jac 7.023459478434121e-11\n",
      "Q hvp 1.539867610117542e-08\n"
     ]
    }
   ],
   "source": [
    "def loss4(μ,Q):\n",
    "    FQ = F.T@Q\n",
    "    Σ  = FQ@FQ.T\n",
    "    λ  = exp(μ+μ0+diag(Σ)/2)\n",
    "    ε  = λ-y*μ\n",
    "    trΛ0Σ = sum(FQ*conm(Λf,FQ))\n",
    "    μΛ0μ  = μ.T @ conv(Λf,μ)\n",
    "    lndΣ  = logdet(Q@Q.T)\n",
    "    return n@ε + trΛ0Σ/2 + μΛ0μ/2 + lndΣ0/2 - lndΣ/2\n",
    "\n",
    "def loss4fht(μ,Q):\n",
    "    FQ = expandAleft(Q)\n",
    "    Σ  = expandA(Q)\n",
    "    λ  = exp(μ+μ0+diag(Σ)/2)\n",
    "    ε  = λ-y*μ\n",
    "    trΛ0Σ = sum(FQ*conm(Λf,FQ))\n",
    "    μΛ0μ  = μ.T @ conv(Λf,μ)\n",
    "    lndΣ  = logdet(Q@Q.T)\n",
    "    return n@ε + trΛ0Σ/2 + μΛ0μ/2 + lndΣ0/2 - lndΣ/2\n",
    "print('loss FHT check',max(abs(loss4(μ,Q)-loss4fht(μ,Q))))\n",
    "\n",
    "# Gradient in μ\n",
    "def Jμ4(μ,Q):\n",
    "    FQ = expandAleft(Q)\n",
    "    Σ  = expandA(Q)\n",
    "    λ  = exp(μ+μ0+diag(Σ)/2)\n",
    "    return n*(λ-y) + conv(Λf,μ)\n",
    "print('μ jac',mean(abs(Jμ4(μ,Q)-grad(loss4,0)(μ,Q))))\n",
    "\n",
    "def Hvμ4(μ,Q,u):\n",
    "    FQ = expandAleft(Q)\n",
    "    nλ = n*exp(μ+μ0+sum(FQ**2,1)/2)\n",
    "    return nλ*u + conv(Λf,u)\n",
    "Hvμ = lambda u: grad(lambda μ: vdot(grad(loss4,0)(μ,Q), u))(μ)\n",
    "print('μ hvp',mean(abs(Hvμ4(μ,Q,u)-Hvμ(u))))\n",
    "\n",
    "# Gradient in Q\n",
    "def JQ4(μ,Q):\n",
    "    FQ = expandAleft(Q)\n",
    "    nλ = n*exp(μ+μ0+sum(FQ**2,1)/2)\n",
    "    P  = ltinv(Q)\n",
    "    \n",
    "    λFQ = nλ[:,None]*FQ\n",
    "    x = λFQ.reshape(L,L,R)\n",
    "    x = fft2(x,axes=(0,1),norm='ortho')\n",
    "    x = real(x) + imag(x)\n",
    "    x = x.reshape(L*L,R)\n",
    "    x = x[keep,:]\n",
    "    FdλFtQ = x #(F*nλ)@F.T@Q\n",
    "    \n",
    "    return F@Λ0Ft@Q + FdλFtQ - P.T\n",
    "print('Q jac',mean(abs(JQ4(μ,Q) -grad(loss4,1)(μ,Q))))\n",
    "\n",
    "def HvQ4(μ,Q,M):\n",
    "    FQ = expandAleft(Q)\n",
    "    nλ = n*exp(μ+μ0+sum(FQ**2,1)/2)\n",
    "    P   = ltinv(Q)\n",
    "    Pt  = P.T\n",
    "    D   = diag(nλ)\n",
    "    r   = nλ * diag(F.T@(M@Q.T)@F)\n",
    "    return (F*nλ)@F.T@M + (F*r)@F.T@Q + F@Λ0Ft@M + Pt@M.T@Pt\n",
    "HvQ = lambda M: grad(lambda Q:vdot(grad(loss4,1)(μ,Q),M))(Q)\n",
    "print('Q hvp',mean(abs(HvQ4(μ,Q,M)-HvQ(M))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "43969737-4b8d-40c8-8f0f-34aa53729adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 702,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd31a497-ef59-48a4-b6da-43874671a2cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
